{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/kusha/OneDrive/Desktop/Task/Deep_Learning_Everyday/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD1CAYAAACrz7WZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMAklEQVR4nO3dX4zl5V3H8fdHtlRjTfk3bnB3cUhY0+BFKZkgpl4oROWPcbloCY2RDdlkb2jSpiZ29caYeAE3oiSGuJHGxWgpqTZsKKmSBWKMgTJYpKVYGQm4uwF2SgFtSFXarxfzkB62szuzO2dm2C/vVzI5v9/zPGfOM8nmvb/89pzZVBWSpF5+bLM3IEmaPuMuSQ0Zd0lqyLhLUkPGXZIaMu6S1NCWzd4AwAUXXFCzs7ObvQ1JOqM8+eST366qmeXm3hVxn52dZX5+frO3IUlnlCQvnmjO2zKS1JBxl6SGjLskNWTcJakh4y5JDa0q7kleSPL1JE8lmR9j5yV5KMlz4/HcMZ4kdyZZSPJ0ksvX8weQJP2oU7ly/5Wquqyq5sb5PuBQVe0EDo1zgGuBneNrL3DXtDYrSVqdtdyW2QUcGMcHgBsmxu+pJY8B5yS5cA2vI0k6Rav9EFMB/5CkgD+vqv3A1qp6acy/DGwdx9uAwxPPPTLGXpoYI8lelq7sueiii05v9xtsdt+XN3sLrbxw2/WbvQWprdXG/Zeq6miSnwYeSvJvk5NVVSP8qzb+gtgPMDc3538HJUlTtKrbMlV1dDweA74EXAG88vbtlvF4bCw/CuyYePr2MSZJ2iArxj3JTyb5qbePgV8DvgEcBHaPZbuB+8fxQeDm8a6ZK4E3Jm7fSJI2wGpuy2wFvpTk7fV/U1VfSfIEcF+SPcCLwI1j/YPAdcAC8CZwy9R3LUk6qRXjXlXPAx9eZvxV4Oplxgu4dSq7kySdFj+hKkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpoVXHPclZSb6W5IFxfnGSx5MsJPlCkrPH+PvH+cKYn12nvUuSTuBUrtw/BTw7cX47cEdVXQK8BuwZ43uA18b4HWOdJGkDrSruSbYD1wN/Mc4DXAV8cSw5ANwwjneNc8b81WO9JGmDrPbK/U+A3wV+MM7PB16vqrfG+RFg2zjeBhwGGPNvjPWSpA2yYtyT/AZwrKqenOYLJ9mbZD7J/OLi4jS/tSS9563myv2jwG8meQG4l6XbMX8KnJNky1izHTg6jo8COwDG/AeBV4//plW1v6rmqmpuZmZmTT+EJOmdVox7Vf1eVW2vqlngJuDhqvot4BHgY2PZbuD+cXxwnDPmH66qmuquJUkntZb3uX8W+EySBZbuqd89xu8Gzh/jnwH2rW2LkqRTtWXlJT9UVY8Cj47j54ErllnzPeDjU9ibJOk0+QlVSWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNrRj3JD+e5KtJ/jXJM0n+cIxfnOTxJAtJvpDk7DH+/nG+MOZn1/lnkCQdZzVX7v8DXFVVHwYuA65JciVwO3BHVV0CvAbsGev3AK+N8TvGOknSBlox7rXku+P0feOrgKuAL47xA8AN43jXOGfMX50k09qwJGllq7rnnuSsJE8Bx4CHgP8AXq+qt8aSI8C2cbwNOAww5t8Azp/iniVJK1hV3Kvq+1V1GbAduAL40FpfOMneJPNJ5hcXF9f67SRJE07p3TJV9TrwCPCLwDlJtoyp7cDRcXwU2AEw5j8IvLrM99pfVXNVNTczM3N6u5ckLWs175aZSXLOOP4J4FeBZ1mK/MfGst3A/eP44DhnzD9cVTXFPUuSVrBl5SVcCBxIchZLfxncV1UPJPkmcG+SPwK+Btw91t8N/FWSBeA7wE3rsG9J0kmsGPeqehr4yDLjz7N0//348e8BH5/K7iRJp8VPqEpSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJamg1n1CV9C43u+/Lm72FVl647frN3sKaeeUuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpoRXjnmRHkkeSfDPJM0k+NcbPS/JQkufG47ljPEnuTLKQ5Okkl6/3DyFJeqfVXLm/BfxOVV0KXAncmuRSYB9wqKp2AofGOcC1wM7xtRe4a+q7liSd1Ipxr6qXqupfxvF/A88C24BdwIGx7ABwwzjeBdxTSx4Dzkly4bQ3Lkk6sVO6555kFvgI8DiwtapeGlMvA1vH8Tbg8MTTjowxSdIGWXXck3wA+Fvg01X1X5NzVVVAncoLJ9mbZD7J/OLi4qk8VZK0glXFPcn7WAr7X1fV343hV96+3TIej43xo8COiadvH2PvUFX7q2ququZmZmZOd/+SpGWs5t0yAe4Gnq2qP56YOgjsHse7gfsnxm8e75q5Enhj4vaNJGkDbFnFmo8Cvw18PclTY+z3gduA+5LsAV4EbhxzDwLXAQvAm8At09ywJGllK8a9qv4JyAmmr15mfQG3rnFfkqQ18BOqktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaWjHuST6X5FiSb0yMnZfkoSTPjcdzx3iS3JlkIcnTSS5fz81Lkpa3miv3vwSuOW5sH3CoqnYCh8Y5wLXAzvG1F7hrOtuUJJ2KFeNeVf8IfOe44V3AgXF8ALhhYvyeWvIYcE6SC6e0V0nSKp3uPfetVfXSOH4Z2DqOtwGHJ9YdGWOSpA205n9QraoC6lSfl2Rvkvkk84uLi2vdhiRpwunG/ZW3b7eMx2Nj/CiwY2Ld9jH2I6pqf1XNVdXczMzMaW5DkrSc0437QWD3ON4N3D8xfvN418yVwBsTt28kSRtky0oLknwe+GXggiRHgD8AbgPuS7IHeBG4cSx/ELgOWADeBG5Zhz1LklawYtyr6hMnmLp6mbUF3LrWTUmS1sZPqEpSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JD6xL3JNck+VaShST71uM1JEknNvW4JzkL+DPgWuBS4BNJLp3260iSTmw9rtyvABaq6vmq+l/gXmDXOryOJOkEtqzD99wGHJ44PwL8wvGLkuwF9o7T7yb51jrs5b3qAuDbm72JleT2zd6BNoF/NqfrZ080sR5xX5Wq2g/s36zX7yzJfFXNbfY+pOP5Z3PjrMdtmaPAjonz7WNMkrRB1iPuTwA7k1yc5GzgJuDgOryOJOkEpn5bpqreSvJJ4O+Bs4DPVdUz034dnZS3u/Ru5Z/NDZKq2uw9SJKmzE+oSlJDxl2SGjLuktTQpr3PXdOR5EMsfQJ42xg6Chysqmc3b1eSNptX7mewJJ9l6dc7BPjq+ArweX9hm97Nktyy2XvoznfLnMGS/Dvw81X1f8eNnw08U1U7N2dn0skl+c+qumiz99GZt2XObD8AfgZ48bjxC8ectGmSPH2iKWDrRu7lvci4n9k+DRxK8hw//GVtFwGXAJ/crE1Jw1bg14HXjhsP8M8bv533FuN+BquqryT5OZZ+zfLkP6g+UVXf37ydSQA8AHygqp46fiLJoxu+m/cY77lLUkO+W0aSGjLuktSQcZekhoy7JDVk3CWpof8HIOCYRf7kAgQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Outcome'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=data.iloc[:,0:8]\n",
    "response=data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8) (614,)\n",
      "(154, 8) (154,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(predictors,response,test_size=0.2)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel=Sequential()\n",
    "kerasmodel.add(Dense(12,input_dim=8,activation='relu'))\n",
    "kerasmodel.add(Dense(8,activation='relu'))\n",
    "kerasmodel.add(Dense(1,activation='sigmoid')) \n",
    "\n",
    "\n",
    "\n",
    "kerasmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 1s 2ms/step - loss: 4.4392 - accuracy: 0.3844\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.5176 - accuracy: 0.4658\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.0328 - accuracy: 0.5717\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.9045 - accuracy: 0.6221\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8908 - accuracy: 0.5993\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.8367 - accuracy: 0.6287\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7939 - accuracy: 0.6189\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7622 - accuracy: 0.6238\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7554 - accuracy: 0.6270\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7349 - accuracy: 0.6221\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7370 - accuracy: 0.6368\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7256 - accuracy: 0.6303\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7284 - accuracy: 0.6287\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.6498\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.6417\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.6417\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.6547\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6774 - accuracy: 0.6303\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6384\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6580\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6450\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6694\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6661\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.6352\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6661\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6629\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6759\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6840\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6743\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6743\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6645\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.6726\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6808\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6792\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6775\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6710\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6678\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6694\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6873\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6596\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6743\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.6678\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6857\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6808\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6857\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6906\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6678\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6743\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7003\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7052\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.7068\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6792\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.6873\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.6987\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7052\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6987\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7003\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6857\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7199\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.6694\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6971\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.6987\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7036\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7264\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7003\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6971\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6645\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6775\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.6906\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7052\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7117\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7362\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7231\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7020\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6971\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6938\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7036\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6922\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7231\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.6889\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7068\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7215\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.6938\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7215\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.6971\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7199\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7020\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.7052\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7068\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7329\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7329\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7150\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7199\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7068\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7150\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7166\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7166\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7362\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7264\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7199\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7182\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7215\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7459\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7134\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7296\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7003\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7345\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7199\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7410\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7264\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7199\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7182\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7296\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7427\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7443\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7313\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7280\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7345\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7199\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7378\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7410\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7427\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7345\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7443\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7313\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7248\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7248\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7394\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7427\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7394\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7280\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7378\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7345\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7248\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7378\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7329\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7182\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7248\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7264\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7362\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7427\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7476\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7150\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7524\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7378\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7557\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7427\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7231\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7476\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123757961d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.fit(x=X_train,y=y_train,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7687\n",
      "Train Accuracy: 76.87\n"
     ]
    }
   ],
   "source": [
    "_,accuracy=kerasmodel.evaluate(X_train,y_train)\n",
    "print('Train Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=kerasmodel.predict(X_test)\n",
    "y_pred = [1 if x >  0.5 else 0 for x in y_pred]\n",
    "\n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
