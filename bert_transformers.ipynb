{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from kaggle_datasets import KaggleDatasets\n",
    "import transformers\n",
    "#from tokenizers import  BertWordPieceTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "# from transformers import TFDistilBertModel\n",
    "\n",
    "# transformer = TFDistilBertModel.from_pretrained('distilbert-base-multilingual-cased') \n",
    "\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load the correct tokenizer for distilbert-base-uncased\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(f\"Tokenizer vocabulary size: {tokenizer.vocab_size}\")  # Should be 30522\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('C:/Users/kusha/OneDrive/Desktop/Task/Deep_Learning_Everyday/BERT_NLP/jigsaw-toxic-comment-train.csv') \n",
    "test_data=pd.read_csv('C:/Users/kusha/OneDrive/Desktop/Task/Deep_Learning_Everyday/BERT_NLP/test.csv')\n",
    "valid_data=pd.read_csv('C:/Users/kusha/OneDrive/Desktop/Task/Deep_Learning_Everyday/BERT_NLP/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223544</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>:Jerome, I see you never got around to this…! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223545</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223546</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223547</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223548</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223549 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "223544  fff8f64043129fa2  :Jerome, I see you never got around to this…! ...   \n",
       "223545  fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...   \n",
       "223546  fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...   \n",
       "223547  fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...   \n",
       "223548  fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "223544      0             0        0       0       0              0  \n",
       "223545      0             0        0       0       0              0  \n",
       "223546      0             0        0       0       0              0  \n",
       "223547      1             0        1       0       1              0  \n",
       "223548      0             0        0       0       0              0  \n",
       "\n",
       "[223549 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fast_encode(texts,tokenizer,chunk_size=256,maxlen=192):\n",
    "#     tokenizer.enable_truncation(maxlen)\n",
    "#     tokenizer.enable_padding(length=maxlen)\n",
    "#     all_ids=[]\n",
    "\n",
    "#     for i in range(0,len(texts),chunk_size):\n",
    "#         text_chunk=texts[i:i+chunk_size].tolist()\n",
    "#         encs=tokenizer.encode_batch(text_chunk)\n",
    "#         all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "#     return np.array(all_ids)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 - Input size: 256, Tokenized size: 256\n",
      "Chunk 1 - Input size: 256, Tokenized size: 256\n",
      "Chunk 2 - Input size: 256, Tokenized size: 256\n",
      "Chunk 3 - Input size: 256, Tokenized size: 256\n",
      "Chunk 4 - Input size: 256, Tokenized size: 256\n",
      "Chunk 5 - Input size: 256, Tokenized size: 256\n",
      "Chunk 6 - Input size: 256, Tokenized size: 256\n",
      "Chunk 7 - Input size: 256, Tokenized size: 256\n",
      "Chunk 8 - Input size: 256, Tokenized size: 256\n",
      "Chunk 9 - Input size: 256, Tokenized size: 256\n",
      "Chunk 10 - Input size: 256, Tokenized size: 256\n",
      "Chunk 11 - Input size: 256, Tokenized size: 256\n",
      "Chunk 12 - Input size: 256, Tokenized size: 256\n",
      "Chunk 13 - Input size: 256, Tokenized size: 256\n",
      "Chunk 14 - Input size: 256, Tokenized size: 256\n",
      "Chunk 15 - Input size: 256, Tokenized size: 256\n",
      "Chunk 16 - Input size: 256, Tokenized size: 256\n",
      "Chunk 17 - Input size: 256, Tokenized size: 256\n",
      "Chunk 18 - Input size: 256, Tokenized size: 256\n",
      "Chunk 19 - Input size: 256, Tokenized size: 256\n",
      "Chunk 20 - Input size: 256, Tokenized size: 256\n",
      "Chunk 21 - Input size: 256, Tokenized size: 256\n",
      "Chunk 22 - Input size: 256, Tokenized size: 256\n",
      "Chunk 23 - Input size: 256, Tokenized size: 256\n",
      "Chunk 24 - Input size: 256, Tokenized size: 256\n",
      "Chunk 25 - Input size: 256, Tokenized size: 256\n",
      "Chunk 26 - Input size: 256, Tokenized size: 256\n",
      "Chunk 27 - Input size: 256, Tokenized size: 256\n",
      "Chunk 28 - Input size: 256, Tokenized size: 256\n",
      "Chunk 29 - Input size: 256, Tokenized size: 256\n",
      "Chunk 30 - Input size: 256, Tokenized size: 256\n",
      "Chunk 31 - Input size: 256, Tokenized size: 256\n",
      "Chunk 32 - Input size: 256, Tokenized size: 256\n",
      "Chunk 33 - Input size: 256, Tokenized size: 256\n",
      "Chunk 34 - Input size: 256, Tokenized size: 256\n",
      "Chunk 35 - Input size: 256, Tokenized size: 256\n",
      "Chunk 36 - Input size: 256, Tokenized size: 256\n",
      "Chunk 37 - Input size: 256, Tokenized size: 256\n",
      "Chunk 38 - Input size: 256, Tokenized size: 256\n",
      "Chunk 39 - Input size: 256, Tokenized size: 256\n",
      "Chunk 40 - Input size: 256, Tokenized size: 256\n",
      "Chunk 41 - Input size: 256, Tokenized size: 256\n",
      "Chunk 42 - Input size: 256, Tokenized size: 256\n",
      "Chunk 43 - Input size: 256, Tokenized size: 256\n",
      "Chunk 44 - Input size: 256, Tokenized size: 256\n",
      "Chunk 45 - Input size: 256, Tokenized size: 256\n",
      "Chunk 46 - Input size: 256, Tokenized size: 256\n",
      "Chunk 47 - Input size: 256, Tokenized size: 256\n",
      "Chunk 48 - Input size: 256, Tokenized size: 256\n",
      "Chunk 49 - Input size: 256, Tokenized size: 256\n",
      "Chunk 50 - Input size: 256, Tokenized size: 256\n",
      "Chunk 51 - Input size: 256, Tokenized size: 256\n",
      "Chunk 52 - Input size: 256, Tokenized size: 256\n",
      "Chunk 53 - Input size: 256, Tokenized size: 256\n",
      "Chunk 54 - Input size: 256, Tokenized size: 256\n",
      "Chunk 55 - Input size: 256, Tokenized size: 256\n",
      "Chunk 56 - Input size: 256, Tokenized size: 256\n",
      "Chunk 57 - Input size: 256, Tokenized size: 256\n",
      "Chunk 58 - Input size: 256, Tokenized size: 256\n",
      "Chunk 59 - Input size: 256, Tokenized size: 256\n",
      "Chunk 60 - Input size: 256, Tokenized size: 256\n",
      "Chunk 61 - Input size: 256, Tokenized size: 256\n",
      "Chunk 62 - Input size: 256, Tokenized size: 256\n",
      "Chunk 63 - Input size: 256, Tokenized size: 256\n",
      "Chunk 64 - Input size: 256, Tokenized size: 256\n",
      "Chunk 65 - Input size: 256, Tokenized size: 256\n",
      "Chunk 66 - Input size: 256, Tokenized size: 256\n",
      "Chunk 67 - Input size: 256, Tokenized size: 256\n",
      "Chunk 68 - Input size: 256, Tokenized size: 256\n",
      "Chunk 69 - Input size: 256, Tokenized size: 256\n",
      "Chunk 70 - Input size: 256, Tokenized size: 256\n",
      "Chunk 71 - Input size: 256, Tokenized size: 256\n",
      "Chunk 72 - Input size: 256, Tokenized size: 256\n",
      "Chunk 73 - Input size: 256, Tokenized size: 256\n",
      "Chunk 74 - Input size: 256, Tokenized size: 256\n",
      "Chunk 75 - Input size: 256, Tokenized size: 256\n",
      "Chunk 76 - Input size: 256, Tokenized size: 256\n",
      "Chunk 77 - Input size: 256, Tokenized size: 256\n",
      "Chunk 78 - Input size: 256, Tokenized size: 256\n",
      "Chunk 79 - Input size: 256, Tokenized size: 256\n",
      "Chunk 80 - Input size: 256, Tokenized size: 256\n",
      "Chunk 81 - Input size: 256, Tokenized size: 256\n",
      "Chunk 82 - Input size: 256, Tokenized size: 256\n",
      "Chunk 83 - Input size: 256, Tokenized size: 256\n",
      "Chunk 84 - Input size: 256, Tokenized size: 256\n",
      "Chunk 85 - Input size: 256, Tokenized size: 256\n",
      "Chunk 86 - Input size: 256, Tokenized size: 256\n",
      "Chunk 87 - Input size: 256, Tokenized size: 256\n",
      "Chunk 88 - Input size: 256, Tokenized size: 256\n",
      "Chunk 89 - Input size: 256, Tokenized size: 256\n",
      "Chunk 90 - Input size: 256, Tokenized size: 256\n",
      "Chunk 91 - Input size: 256, Tokenized size: 256\n",
      "Chunk 92 - Input size: 256, Tokenized size: 256\n",
      "Chunk 93 - Input size: 256, Tokenized size: 256\n",
      "Chunk 94 - Input size: 256, Tokenized size: 256\n",
      "Chunk 95 - Input size: 256, Tokenized size: 256\n",
      "Chunk 96 - Input size: 256, Tokenized size: 256\n",
      "Chunk 97 - Input size: 256, Tokenized size: 256\n",
      "Chunk 98 - Input size: 256, Tokenized size: 256\n",
      "Chunk 99 - Input size: 256, Tokenized size: 256\n",
      "Chunk 100 - Input size: 256, Tokenized size: 256\n",
      "Chunk 101 - Input size: 256, Tokenized size: 256\n",
      "Chunk 102 - Input size: 256, Tokenized size: 256\n",
      "Chunk 103 - Input size: 256, Tokenized size: 256\n",
      "Chunk 104 - Input size: 256, Tokenized size: 256\n",
      "Chunk 105 - Input size: 256, Tokenized size: 256\n",
      "Chunk 106 - Input size: 256, Tokenized size: 256\n",
      "Chunk 107 - Input size: 256, Tokenized size: 256\n",
      "Chunk 108 - Input size: 256, Tokenized size: 256\n",
      "Chunk 109 - Input size: 256, Tokenized size: 256\n",
      "Chunk 110 - Input size: 256, Tokenized size: 256\n",
      "Chunk 111 - Input size: 256, Tokenized size: 256\n",
      "Chunk 112 - Input size: 256, Tokenized size: 256\n",
      "Chunk 113 - Input size: 256, Tokenized size: 256\n",
      "Chunk 114 - Input size: 256, Tokenized size: 256\n",
      "Chunk 115 - Input size: 256, Tokenized size: 256\n",
      "Chunk 116 - Input size: 256, Tokenized size: 256\n",
      "Chunk 117 - Input size: 256, Tokenized size: 256\n",
      "Chunk 118 - Input size: 256, Tokenized size: 256\n",
      "Chunk 119 - Input size: 256, Tokenized size: 256\n",
      "Chunk 120 - Input size: 256, Tokenized size: 256\n",
      "Chunk 121 - Input size: 256, Tokenized size: 256\n",
      "Chunk 122 - Input size: 256, Tokenized size: 256\n",
      "Chunk 123 - Input size: 256, Tokenized size: 256\n",
      "Chunk 124 - Input size: 256, Tokenized size: 256\n",
      "Chunk 125 - Input size: 256, Tokenized size: 256\n",
      "Chunk 126 - Input size: 256, Tokenized size: 256\n",
      "Chunk 127 - Input size: 256, Tokenized size: 256\n",
      "Chunk 128 - Input size: 256, Tokenized size: 256\n",
      "Chunk 129 - Input size: 256, Tokenized size: 256\n",
      "Chunk 130 - Input size: 256, Tokenized size: 256\n",
      "Chunk 131 - Input size: 256, Tokenized size: 256\n",
      "Chunk 132 - Input size: 256, Tokenized size: 256\n",
      "Chunk 133 - Input size: 256, Tokenized size: 256\n",
      "Chunk 134 - Input size: 256, Tokenized size: 256\n",
      "Chunk 135 - Input size: 256, Tokenized size: 256\n",
      "Chunk 136 - Input size: 256, Tokenized size: 256\n",
      "Chunk 137 - Input size: 256, Tokenized size: 256\n",
      "Chunk 138 - Input size: 256, Tokenized size: 256\n",
      "Chunk 139 - Input size: 256, Tokenized size: 256\n",
      "Chunk 140 - Input size: 256, Tokenized size: 256\n",
      "Chunk 141 - Input size: 256, Tokenized size: 256\n",
      "Chunk 142 - Input size: 256, Tokenized size: 256\n",
      "Chunk 143 - Input size: 256, Tokenized size: 256\n",
      "Chunk 144 - Input size: 256, Tokenized size: 256\n",
      "Chunk 145 - Input size: 256, Tokenized size: 256\n",
      "Chunk 146 - Input size: 256, Tokenized size: 256\n",
      "Chunk 147 - Input size: 256, Tokenized size: 256\n",
      "Chunk 148 - Input size: 256, Tokenized size: 256\n",
      "Chunk 149 - Input size: 256, Tokenized size: 256\n",
      "Chunk 150 - Input size: 256, Tokenized size: 256\n",
      "Chunk 151 - Input size: 256, Tokenized size: 256\n",
      "Chunk 152 - Input size: 256, Tokenized size: 256\n",
      "Chunk 153 - Input size: 256, Tokenized size: 256\n",
      "Chunk 154 - Input size: 256, Tokenized size: 256\n",
      "Chunk 155 - Input size: 256, Tokenized size: 256\n",
      "Chunk 156 - Input size: 256, Tokenized size: 256\n",
      "Chunk 157 - Input size: 256, Tokenized size: 256\n",
      "Chunk 158 - Input size: 256, Tokenized size: 256\n",
      "Chunk 159 - Input size: 256, Tokenized size: 256\n",
      "Chunk 160 - Input size: 256, Tokenized size: 256\n",
      "Chunk 161 - Input size: 256, Tokenized size: 256\n",
      "Chunk 162 - Input size: 256, Tokenized size: 256\n",
      "Chunk 163 - Input size: 256, Tokenized size: 256\n",
      "Chunk 164 - Input size: 256, Tokenized size: 256\n",
      "Chunk 165 - Input size: 256, Tokenized size: 256\n",
      "Chunk 166 - Input size: 256, Tokenized size: 256\n",
      "Chunk 167 - Input size: 256, Tokenized size: 256\n",
      "Chunk 168 - Input size: 256, Tokenized size: 256\n",
      "Chunk 169 - Input size: 256, Tokenized size: 256\n",
      "Chunk 170 - Input size: 256, Tokenized size: 256\n",
      "Chunk 171 - Input size: 256, Tokenized size: 256\n",
      "Chunk 172 - Input size: 256, Tokenized size: 256\n",
      "Chunk 173 - Input size: 256, Tokenized size: 256\n",
      "Chunk 174 - Input size: 256, Tokenized size: 256\n",
      "Chunk 175 - Input size: 256, Tokenized size: 256\n",
      "Chunk 176 - Input size: 256, Tokenized size: 256\n",
      "Chunk 177 - Input size: 256, Tokenized size: 256\n",
      "Chunk 178 - Input size: 256, Tokenized size: 256\n",
      "Chunk 179 - Input size: 256, Tokenized size: 256\n",
      "Chunk 180 - Input size: 256, Tokenized size: 256\n",
      "Chunk 181 - Input size: 256, Tokenized size: 256\n",
      "Chunk 182 - Input size: 256, Tokenized size: 256\n",
      "Chunk 183 - Input size: 256, Tokenized size: 256\n",
      "Chunk 184 - Input size: 256, Tokenized size: 256\n",
      "Chunk 185 - Input size: 256, Tokenized size: 256\n",
      "Chunk 186 - Input size: 256, Tokenized size: 256\n",
      "Chunk 187 - Input size: 256, Tokenized size: 256\n",
      "Chunk 188 - Input size: 256, Tokenized size: 256\n",
      "Chunk 189 - Input size: 256, Tokenized size: 256\n",
      "Chunk 190 - Input size: 256, Tokenized size: 256\n",
      "Chunk 191 - Input size: 256, Tokenized size: 256\n",
      "Chunk 192 - Input size: 256, Tokenized size: 256\n",
      "Chunk 193 - Input size: 256, Tokenized size: 256\n",
      "Chunk 194 - Input size: 256, Tokenized size: 256\n",
      "Chunk 195 - Input size: 256, Tokenized size: 256\n",
      "Chunk 196 - Input size: 256, Tokenized size: 256\n",
      "Chunk 197 - Input size: 256, Tokenized size: 256\n",
      "Chunk 198 - Input size: 256, Tokenized size: 256\n",
      "Chunk 199 - Input size: 256, Tokenized size: 256\n",
      "Chunk 200 - Input size: 256, Tokenized size: 256\n",
      "Chunk 201 - Input size: 256, Tokenized size: 256\n",
      "Chunk 202 - Input size: 256, Tokenized size: 256\n",
      "Chunk 203 - Input size: 256, Tokenized size: 256\n",
      "Chunk 204 - Input size: 256, Tokenized size: 256\n",
      "Chunk 205 - Input size: 256, Tokenized size: 256\n",
      "Chunk 206 - Input size: 256, Tokenized size: 256\n",
      "Chunk 207 - Input size: 256, Tokenized size: 256\n",
      "Chunk 208 - Input size: 256, Tokenized size: 256\n",
      "Chunk 209 - Input size: 256, Tokenized size: 256\n",
      "Chunk 210 - Input size: 256, Tokenized size: 256\n",
      "Chunk 211 - Input size: 256, Tokenized size: 256\n",
      "Chunk 212 - Input size: 256, Tokenized size: 256\n",
      "Chunk 213 - Input size: 256, Tokenized size: 256\n",
      "Chunk 214 - Input size: 256, Tokenized size: 256\n",
      "Chunk 215 - Input size: 256, Tokenized size: 256\n",
      "Chunk 216 - Input size: 256, Tokenized size: 256\n",
      "Chunk 217 - Input size: 256, Tokenized size: 256\n",
      "Chunk 218 - Input size: 256, Tokenized size: 256\n",
      "Chunk 219 - Input size: 256, Tokenized size: 256\n",
      "Chunk 220 - Input size: 256, Tokenized size: 256\n",
      "Chunk 221 - Input size: 256, Tokenized size: 256\n",
      "Chunk 222 - Input size: 256, Tokenized size: 256\n",
      "Chunk 223 - Input size: 256, Tokenized size: 256\n",
      "Chunk 224 - Input size: 256, Tokenized size: 256\n",
      "Chunk 225 - Input size: 256, Tokenized size: 256\n",
      "Chunk 226 - Input size: 256, Tokenized size: 256\n",
      "Chunk 227 - Input size: 256, Tokenized size: 256\n",
      "Chunk 228 - Input size: 256, Tokenized size: 256\n",
      "Chunk 229 - Input size: 256, Tokenized size: 256\n",
      "Chunk 230 - Input size: 256, Tokenized size: 256\n",
      "Chunk 231 - Input size: 256, Tokenized size: 256\n",
      "Chunk 232 - Input size: 256, Tokenized size: 256\n",
      "Chunk 233 - Input size: 256, Tokenized size: 256\n",
      "Chunk 234 - Input size: 256, Tokenized size: 256\n",
      "Chunk 235 - Input size: 256, Tokenized size: 256\n",
      "Chunk 236 - Input size: 256, Tokenized size: 256\n",
      "Chunk 237 - Input size: 256, Tokenized size: 256\n",
      "Chunk 238 - Input size: 256, Tokenized size: 256\n",
      "Chunk 239 - Input size: 256, Tokenized size: 256\n",
      "Chunk 240 - Input size: 256, Tokenized size: 256\n",
      "Chunk 241 - Input size: 256, Tokenized size: 256\n",
      "Chunk 242 - Input size: 256, Tokenized size: 256\n",
      "Chunk 243 - Input size: 256, Tokenized size: 256\n",
      "Chunk 244 - Input size: 256, Tokenized size: 256\n",
      "Chunk 245 - Input size: 256, Tokenized size: 256\n",
      "Chunk 246 - Input size: 256, Tokenized size: 256\n",
      "Chunk 247 - Input size: 256, Tokenized size: 256\n",
      "Chunk 248 - Input size: 256, Tokenized size: 256\n",
      "Chunk 249 - Input size: 256, Tokenized size: 256\n",
      "Chunk 250 - Input size: 256, Tokenized size: 256\n",
      "Chunk 251 - Input size: 256, Tokenized size: 256\n",
      "Chunk 252 - Input size: 256, Tokenized size: 256\n",
      "Chunk 253 - Input size: 256, Tokenized size: 256\n",
      "Chunk 254 - Input size: 256, Tokenized size: 256\n",
      "Chunk 255 - Input size: 256, Tokenized size: 256\n",
      "Chunk 256 - Input size: 256, Tokenized size: 256\n",
      "Chunk 257 - Input size: 256, Tokenized size: 256\n",
      "Chunk 258 - Input size: 256, Tokenized size: 256\n",
      "Chunk 259 - Input size: 256, Tokenized size: 256\n",
      "Chunk 260 - Input size: 256, Tokenized size: 256\n",
      "Chunk 261 - Input size: 256, Tokenized size: 256\n",
      "Chunk 262 - Input size: 256, Tokenized size: 256\n",
      "Chunk 263 - Input size: 256, Tokenized size: 256\n",
      "Chunk 264 - Input size: 256, Tokenized size: 256\n",
      "Chunk 265 - Input size: 256, Tokenized size: 256\n",
      "Chunk 266 - Input size: 256, Tokenized size: 256\n",
      "Chunk 267 - Input size: 256, Tokenized size: 256\n",
      "Chunk 268 - Input size: 256, Tokenized size: 256\n",
      "Chunk 269 - Input size: 256, Tokenized size: 256\n",
      "Chunk 270 - Input size: 256, Tokenized size: 256\n",
      "Chunk 271 - Input size: 256, Tokenized size: 256\n",
      "Chunk 272 - Input size: 256, Tokenized size: 256\n",
      "Chunk 273 - Input size: 256, Tokenized size: 256\n",
      "Chunk 274 - Input size: 256, Tokenized size: 256\n",
      "Chunk 275 - Input size: 256, Tokenized size: 256\n",
      "Chunk 276 - Input size: 256, Tokenized size: 256\n",
      "Chunk 277 - Input size: 256, Tokenized size: 256\n",
      "Chunk 278 - Input size: 256, Tokenized size: 256\n",
      "Chunk 279 - Input size: 256, Tokenized size: 256\n",
      "Chunk 280 - Input size: 256, Tokenized size: 256\n",
      "Chunk 281 - Input size: 256, Tokenized size: 256\n",
      "Chunk 282 - Input size: 256, Tokenized size: 256\n",
      "Chunk 283 - Input size: 256, Tokenized size: 256\n",
      "Chunk 284 - Input size: 256, Tokenized size: 256\n",
      "Chunk 285 - Input size: 256, Tokenized size: 256\n",
      "Chunk 286 - Input size: 256, Tokenized size: 256\n",
      "Chunk 287 - Input size: 256, Tokenized size: 256\n",
      "Chunk 288 - Input size: 256, Tokenized size: 256\n",
      "Chunk 289 - Input size: 256, Tokenized size: 256\n",
      "Chunk 290 - Input size: 256, Tokenized size: 256\n",
      "Chunk 291 - Input size: 256, Tokenized size: 256\n",
      "Chunk 292 - Input size: 256, Tokenized size: 256\n",
      "Chunk 293 - Input size: 256, Tokenized size: 256\n",
      "Chunk 294 - Input size: 256, Tokenized size: 256\n",
      "Chunk 295 - Input size: 256, Tokenized size: 256\n",
      "Chunk 296 - Input size: 256, Tokenized size: 256\n",
      "Chunk 297 - Input size: 256, Tokenized size: 256\n",
      "Chunk 298 - Input size: 256, Tokenized size: 256\n",
      "Chunk 299 - Input size: 256, Tokenized size: 256\n",
      "Chunk 300 - Input size: 256, Tokenized size: 256\n",
      "Chunk 301 - Input size: 256, Tokenized size: 256\n",
      "Chunk 302 - Input size: 256, Tokenized size: 256\n",
      "Chunk 303 - Input size: 256, Tokenized size: 256\n",
      "Chunk 304 - Input size: 256, Tokenized size: 256\n",
      "Chunk 305 - Input size: 256, Tokenized size: 256\n",
      "Chunk 306 - Input size: 256, Tokenized size: 256\n",
      "Chunk 307 - Input size: 256, Tokenized size: 256\n",
      "Chunk 308 - Input size: 256, Tokenized size: 256\n",
      "Chunk 309 - Input size: 256, Tokenized size: 256\n",
      "Chunk 310 - Input size: 256, Tokenized size: 256\n",
      "Chunk 311 - Input size: 256, Tokenized size: 256\n",
      "Chunk 312 - Input size: 256, Tokenized size: 256\n",
      "Chunk 313 - Input size: 256, Tokenized size: 256\n",
      "Chunk 314 - Input size: 256, Tokenized size: 256\n",
      "Chunk 315 - Input size: 256, Tokenized size: 256\n",
      "Chunk 316 - Input size: 256, Tokenized size: 256\n",
      "Chunk 317 - Input size: 256, Tokenized size: 256\n",
      "Chunk 318 - Input size: 256, Tokenized size: 256\n",
      "Chunk 319 - Input size: 256, Tokenized size: 256\n",
      "Chunk 320 - Input size: 256, Tokenized size: 256\n",
      "Chunk 321 - Input size: 256, Tokenized size: 256\n",
      "Chunk 322 - Input size: 256, Tokenized size: 256\n",
      "Chunk 323 - Input size: 256, Tokenized size: 256\n",
      "Chunk 324 - Input size: 256, Tokenized size: 256\n",
      "Chunk 325 - Input size: 256, Tokenized size: 256\n",
      "Chunk 326 - Input size: 256, Tokenized size: 256\n",
      "Chunk 327 - Input size: 256, Tokenized size: 256\n",
      "Chunk 328 - Input size: 256, Tokenized size: 256\n",
      "Chunk 329 - Input size: 256, Tokenized size: 256\n",
      "Chunk 330 - Input size: 256, Tokenized size: 256\n",
      "Chunk 331 - Input size: 256, Tokenized size: 256\n",
      "Chunk 332 - Input size: 256, Tokenized size: 256\n",
      "Chunk 333 - Input size: 256, Tokenized size: 256\n",
      "Chunk 334 - Input size: 256, Tokenized size: 256\n",
      "Chunk 335 - Input size: 256, Tokenized size: 256\n",
      "Chunk 336 - Input size: 256, Tokenized size: 256\n",
      "Chunk 337 - Input size: 256, Tokenized size: 256\n",
      "Chunk 338 - Input size: 256, Tokenized size: 256\n",
      "Chunk 339 - Input size: 256, Tokenized size: 256\n",
      "Chunk 340 - Input size: 256, Tokenized size: 256\n",
      "Chunk 341 - Input size: 256, Tokenized size: 256\n",
      "Chunk 342 - Input size: 256, Tokenized size: 256\n",
      "Chunk 343 - Input size: 256, Tokenized size: 256\n",
      "Chunk 344 - Input size: 256, Tokenized size: 256\n",
      "Chunk 345 - Input size: 256, Tokenized size: 256\n",
      "Chunk 346 - Input size: 256, Tokenized size: 256\n",
      "Chunk 347 - Input size: 256, Tokenized size: 256\n",
      "Chunk 348 - Input size: 256, Tokenized size: 256\n",
      "Chunk 349 - Input size: 256, Tokenized size: 256\n",
      "Chunk 350 - Input size: 256, Tokenized size: 256\n",
      "Chunk 351 - Input size: 256, Tokenized size: 256\n",
      "Chunk 352 - Input size: 256, Tokenized size: 256\n",
      "Chunk 353 - Input size: 256, Tokenized size: 256\n",
      "Chunk 354 - Input size: 256, Tokenized size: 256\n",
      "Chunk 355 - Input size: 256, Tokenized size: 256\n",
      "Chunk 356 - Input size: 256, Tokenized size: 256\n",
      "Chunk 357 - Input size: 256, Tokenized size: 256\n",
      "Chunk 358 - Input size: 256, Tokenized size: 256\n",
      "Chunk 359 - Input size: 256, Tokenized size: 256\n",
      "Chunk 360 - Input size: 256, Tokenized size: 256\n",
      "Chunk 361 - Input size: 256, Tokenized size: 256\n",
      "Chunk 362 - Input size: 256, Tokenized size: 256\n",
      "Chunk 363 - Input size: 256, Tokenized size: 256\n",
      "Chunk 364 - Input size: 256, Tokenized size: 256\n",
      "Chunk 365 - Input size: 256, Tokenized size: 256\n",
      "Chunk 366 - Input size: 256, Tokenized size: 256\n",
      "Chunk 367 - Input size: 256, Tokenized size: 256\n",
      "Chunk 368 - Input size: 256, Tokenized size: 256\n",
      "Chunk 369 - Input size: 256, Tokenized size: 256\n",
      "Chunk 370 - Input size: 256, Tokenized size: 256\n",
      "Chunk 371 - Input size: 256, Tokenized size: 256\n",
      "Chunk 372 - Input size: 256, Tokenized size: 256\n",
      "Chunk 373 - Input size: 256, Tokenized size: 256\n",
      "Chunk 374 - Input size: 256, Tokenized size: 256\n",
      "Chunk 375 - Input size: 256, Tokenized size: 256\n",
      "Chunk 376 - Input size: 256, Tokenized size: 256\n",
      "Chunk 377 - Input size: 256, Tokenized size: 256\n",
      "Chunk 378 - Input size: 256, Tokenized size: 256\n",
      "Chunk 379 - Input size: 256, Tokenized size: 256\n",
      "Chunk 380 - Input size: 256, Tokenized size: 256\n",
      "Chunk 381 - Input size: 256, Tokenized size: 256\n",
      "Chunk 382 - Input size: 256, Tokenized size: 256\n",
      "Chunk 383 - Input size: 256, Tokenized size: 256\n",
      "Chunk 384 - Input size: 256, Tokenized size: 256\n",
      "Chunk 385 - Input size: 256, Tokenized size: 256\n",
      "Chunk 386 - Input size: 256, Tokenized size: 256\n",
      "Chunk 387 - Input size: 256, Tokenized size: 256\n",
      "Chunk 388 - Input size: 256, Tokenized size: 256\n",
      "Chunk 389 - Input size: 256, Tokenized size: 256\n",
      "Chunk 390 - Input size: 256, Tokenized size: 256\n",
      "Chunk 391 - Input size: 256, Tokenized size: 256\n",
      "Chunk 392 - Input size: 256, Tokenized size: 256\n",
      "Chunk 393 - Input size: 256, Tokenized size: 256\n",
      "Chunk 394 - Input size: 256, Tokenized size: 256\n",
      "Chunk 395 - Input size: 256, Tokenized size: 256\n",
      "Chunk 396 - Input size: 256, Tokenized size: 256\n",
      "Chunk 397 - Input size: 256, Tokenized size: 256\n",
      "Chunk 398 - Input size: 256, Tokenized size: 256\n",
      "Chunk 399 - Input size: 256, Tokenized size: 256\n",
      "Chunk 400 - Input size: 256, Tokenized size: 256\n",
      "Chunk 401 - Input size: 256, Tokenized size: 256\n",
      "Chunk 402 - Input size: 256, Tokenized size: 256\n",
      "Chunk 403 - Input size: 256, Tokenized size: 256\n",
      "Chunk 404 - Input size: 256, Tokenized size: 256\n",
      "Chunk 405 - Input size: 256, Tokenized size: 256\n",
      "Chunk 406 - Input size: 256, Tokenized size: 256\n",
      "Chunk 407 - Input size: 256, Tokenized size: 256\n",
      "Chunk 408 - Input size: 256, Tokenized size: 256\n",
      "Chunk 409 - Input size: 256, Tokenized size: 256\n",
      "Chunk 410 - Input size: 256, Tokenized size: 256\n",
      "Chunk 411 - Input size: 256, Tokenized size: 256\n",
      "Chunk 412 - Input size: 256, Tokenized size: 256\n",
      "Chunk 413 - Input size: 256, Tokenized size: 256\n",
      "Chunk 414 - Input size: 256, Tokenized size: 256\n",
      "Chunk 415 - Input size: 256, Tokenized size: 256\n",
      "Chunk 416 - Input size: 256, Tokenized size: 256\n",
      "Chunk 417 - Input size: 256, Tokenized size: 256\n",
      "Chunk 418 - Input size: 256, Tokenized size: 256\n",
      "Chunk 419 - Input size: 256, Tokenized size: 256\n",
      "Chunk 420 - Input size: 256, Tokenized size: 256\n",
      "Chunk 421 - Input size: 256, Tokenized size: 256\n",
      "Chunk 422 - Input size: 256, Tokenized size: 256\n",
      "Chunk 423 - Input size: 256, Tokenized size: 256\n",
      "Chunk 424 - Input size: 256, Tokenized size: 256\n",
      "Chunk 425 - Input size: 256, Tokenized size: 256\n",
      "Chunk 426 - Input size: 256, Tokenized size: 256\n",
      "Chunk 427 - Input size: 256, Tokenized size: 256\n",
      "Chunk 428 - Input size: 256, Tokenized size: 256\n",
      "Chunk 429 - Input size: 256, Tokenized size: 256\n",
      "Chunk 430 - Input size: 256, Tokenized size: 256\n",
      "Chunk 431 - Input size: 256, Tokenized size: 256\n",
      "Chunk 432 - Input size: 256, Tokenized size: 256\n",
      "Chunk 433 - Input size: 256, Tokenized size: 256\n",
      "Chunk 434 - Input size: 256, Tokenized size: 256\n",
      "Chunk 435 - Input size: 256, Tokenized size: 256\n",
      "Chunk 436 - Input size: 256, Tokenized size: 256\n",
      "Chunk 437 - Input size: 256, Tokenized size: 256\n",
      "Chunk 438 - Input size: 256, Tokenized size: 256\n",
      "Chunk 439 - Input size: 256, Tokenized size: 256\n",
      "Chunk 440 - Input size: 256, Tokenized size: 256\n",
      "Chunk 441 - Input size: 256, Tokenized size: 256\n",
      "Chunk 442 - Input size: 256, Tokenized size: 256\n",
      "Chunk 443 - Input size: 256, Tokenized size: 256\n",
      "Chunk 444 - Input size: 256, Tokenized size: 256\n",
      "Chunk 445 - Input size: 256, Tokenized size: 256\n",
      "Chunk 446 - Input size: 256, Tokenized size: 256\n",
      "Chunk 447 - Input size: 256, Tokenized size: 256\n",
      "Chunk 448 - Input size: 256, Tokenized size: 256\n",
      "Chunk 449 - Input size: 256, Tokenized size: 256\n",
      "Chunk 450 - Input size: 256, Tokenized size: 256\n",
      "Chunk 451 - Input size: 256, Tokenized size: 256\n",
      "Chunk 452 - Input size: 256, Tokenized size: 256\n",
      "Chunk 453 - Input size: 256, Tokenized size: 256\n",
      "Chunk 454 - Input size: 256, Tokenized size: 256\n",
      "Chunk 455 - Input size: 256, Tokenized size: 256\n",
      "Chunk 456 - Input size: 256, Tokenized size: 256\n",
      "Chunk 457 - Input size: 256, Tokenized size: 256\n",
      "Chunk 458 - Input size: 256, Tokenized size: 256\n",
      "Chunk 459 - Input size: 256, Tokenized size: 256\n",
      "Chunk 460 - Input size: 256, Tokenized size: 256\n",
      "Chunk 461 - Input size: 256, Tokenized size: 256\n",
      "Chunk 462 - Input size: 256, Tokenized size: 256\n",
      "Chunk 463 - Input size: 256, Tokenized size: 256\n",
      "Chunk 464 - Input size: 256, Tokenized size: 256\n",
      "Chunk 465 - Input size: 256, Tokenized size: 256\n",
      "Chunk 466 - Input size: 256, Tokenized size: 256\n",
      "Chunk 467 - Input size: 256, Tokenized size: 256\n",
      "Chunk 468 - Input size: 256, Tokenized size: 256\n",
      "Chunk 469 - Input size: 256, Tokenized size: 256\n",
      "Chunk 470 - Input size: 256, Tokenized size: 256\n",
      "Chunk 471 - Input size: 256, Tokenized size: 256\n",
      "Chunk 472 - Input size: 256, Tokenized size: 256\n",
      "Chunk 473 - Input size: 256, Tokenized size: 256\n",
      "Chunk 474 - Input size: 256, Tokenized size: 256\n",
      "Chunk 475 - Input size: 256, Tokenized size: 256\n",
      "Chunk 476 - Input size: 256, Tokenized size: 256\n",
      "Chunk 477 - Input size: 256, Tokenized size: 256\n",
      "Chunk 478 - Input size: 256, Tokenized size: 256\n",
      "Chunk 479 - Input size: 256, Tokenized size: 256\n",
      "Chunk 480 - Input size: 256, Tokenized size: 256\n",
      "Chunk 481 - Input size: 256, Tokenized size: 256\n",
      "Chunk 482 - Input size: 256, Tokenized size: 256\n",
      "Chunk 483 - Input size: 256, Tokenized size: 256\n",
      "Chunk 484 - Input size: 256, Tokenized size: 256\n",
      "Chunk 485 - Input size: 256, Tokenized size: 256\n",
      "Chunk 486 - Input size: 256, Tokenized size: 256\n",
      "Chunk 487 - Input size: 256, Tokenized size: 256\n",
      "Chunk 488 - Input size: 256, Tokenized size: 256\n",
      "Chunk 489 - Input size: 256, Tokenized size: 256\n",
      "Chunk 490 - Input size: 256, Tokenized size: 256\n",
      "Chunk 491 - Input size: 256, Tokenized size: 256\n",
      "Chunk 492 - Input size: 256, Tokenized size: 256\n",
      "Chunk 493 - Input size: 256, Tokenized size: 256\n",
      "Chunk 494 - Input size: 256, Tokenized size: 256\n",
      "Chunk 495 - Input size: 256, Tokenized size: 256\n",
      "Chunk 496 - Input size: 256, Tokenized size: 256\n",
      "Chunk 497 - Input size: 256, Tokenized size: 256\n",
      "Chunk 498 - Input size: 256, Tokenized size: 256\n",
      "Chunk 499 - Input size: 256, Tokenized size: 256\n",
      "Chunk 500 - Input size: 256, Tokenized size: 256\n",
      "Chunk 501 - Input size: 256, Tokenized size: 256\n",
      "Chunk 502 - Input size: 256, Tokenized size: 256\n",
      "Chunk 503 - Input size: 256, Tokenized size: 256\n",
      "Chunk 504 - Input size: 256, Tokenized size: 256\n",
      "Chunk 505 - Input size: 256, Tokenized size: 256\n",
      "Chunk 506 - Input size: 256, Tokenized size: 256\n",
      "Chunk 507 - Input size: 256, Tokenized size: 256\n",
      "Chunk 508 - Input size: 256, Tokenized size: 256\n",
      "Chunk 509 - Input size: 256, Tokenized size: 256\n",
      "Chunk 510 - Input size: 256, Tokenized size: 256\n",
      "Chunk 511 - Input size: 256, Tokenized size: 256\n",
      "Chunk 512 - Input size: 256, Tokenized size: 256\n",
      "Chunk 513 - Input size: 256, Tokenized size: 256\n",
      "Chunk 514 - Input size: 256, Tokenized size: 256\n",
      "Chunk 515 - Input size: 256, Tokenized size: 256\n",
      "Chunk 516 - Input size: 256, Tokenized size: 256\n",
      "Chunk 517 - Input size: 256, Tokenized size: 256\n",
      "Chunk 518 - Input size: 256, Tokenized size: 256\n",
      "Chunk 519 - Input size: 256, Tokenized size: 256\n",
      "Chunk 520 - Input size: 256, Tokenized size: 256\n",
      "Chunk 521 - Input size: 256, Tokenized size: 256\n",
      "Chunk 522 - Input size: 256, Tokenized size: 256\n",
      "Chunk 523 - Input size: 256, Tokenized size: 256\n",
      "Chunk 524 - Input size: 256, Tokenized size: 256\n",
      "Chunk 525 - Input size: 256, Tokenized size: 256\n",
      "Chunk 526 - Input size: 256, Tokenized size: 256\n",
      "Chunk 527 - Input size: 256, Tokenized size: 256\n",
      "Chunk 528 - Input size: 256, Tokenized size: 256\n",
      "Chunk 529 - Input size: 256, Tokenized size: 256\n",
      "Chunk 530 - Input size: 256, Tokenized size: 256\n",
      "Chunk 531 - Input size: 256, Tokenized size: 256\n",
      "Chunk 532 - Input size: 256, Tokenized size: 256\n",
      "Chunk 533 - Input size: 256, Tokenized size: 256\n",
      "Chunk 534 - Input size: 256, Tokenized size: 256\n",
      "Chunk 535 - Input size: 256, Tokenized size: 256\n",
      "Chunk 536 - Input size: 256, Tokenized size: 256\n",
      "Chunk 537 - Input size: 256, Tokenized size: 256\n",
      "Chunk 538 - Input size: 256, Tokenized size: 256\n",
      "Chunk 539 - Input size: 256, Tokenized size: 256\n",
      "Chunk 540 - Input size: 256, Tokenized size: 256\n",
      "Chunk 541 - Input size: 256, Tokenized size: 256\n",
      "Chunk 542 - Input size: 256, Tokenized size: 256\n",
      "Chunk 543 - Input size: 256, Tokenized size: 256\n",
      "Chunk 544 - Input size: 256, Tokenized size: 256\n",
      "Chunk 545 - Input size: 256, Tokenized size: 256\n",
      "Chunk 546 - Input size: 256, Tokenized size: 256\n",
      "Chunk 547 - Input size: 256, Tokenized size: 256\n",
      "Chunk 548 - Input size: 256, Tokenized size: 256\n",
      "Chunk 549 - Input size: 256, Tokenized size: 256\n",
      "Chunk 550 - Input size: 256, Tokenized size: 256\n",
      "Chunk 551 - Input size: 256, Tokenized size: 256\n",
      "Chunk 552 - Input size: 256, Tokenized size: 256\n",
      "Chunk 553 - Input size: 256, Tokenized size: 256\n",
      "Chunk 554 - Input size: 256, Tokenized size: 256\n",
      "Chunk 555 - Input size: 256, Tokenized size: 256\n",
      "Chunk 556 - Input size: 256, Tokenized size: 256\n",
      "Chunk 557 - Input size: 256, Tokenized size: 256\n",
      "Chunk 558 - Input size: 256, Tokenized size: 256\n",
      "Chunk 559 - Input size: 256, Tokenized size: 256\n",
      "Chunk 560 - Input size: 256, Tokenized size: 256\n",
      "Chunk 561 - Input size: 256, Tokenized size: 256\n",
      "Chunk 562 - Input size: 256, Tokenized size: 256\n",
      "Chunk 563 - Input size: 256, Tokenized size: 256\n",
      "Chunk 564 - Input size: 256, Tokenized size: 256\n",
      "Chunk 565 - Input size: 256, Tokenized size: 256\n",
      "Chunk 566 - Input size: 256, Tokenized size: 256\n",
      "Chunk 567 - Input size: 256, Tokenized size: 256\n",
      "Chunk 568 - Input size: 256, Tokenized size: 256\n",
      "Chunk 569 - Input size: 256, Tokenized size: 256\n",
      "Chunk 570 - Input size: 256, Tokenized size: 256\n",
      "Chunk 571 - Input size: 256, Tokenized size: 256\n",
      "Chunk 572 - Input size: 256, Tokenized size: 256\n",
      "Chunk 573 - Input size: 256, Tokenized size: 256\n",
      "Chunk 574 - Input size: 256, Tokenized size: 256\n",
      "Chunk 575 - Input size: 256, Tokenized size: 256\n",
      "Chunk 576 - Input size: 256, Tokenized size: 256\n",
      "Chunk 577 - Input size: 256, Tokenized size: 256\n",
      "Chunk 578 - Input size: 256, Tokenized size: 256\n",
      "Chunk 579 - Input size: 256, Tokenized size: 256\n",
      "Chunk 580 - Input size: 256, Tokenized size: 256\n",
      "Chunk 581 - Input size: 256, Tokenized size: 256\n",
      "Chunk 582 - Input size: 256, Tokenized size: 256\n",
      "Chunk 583 - Input size: 256, Tokenized size: 256\n",
      "Chunk 584 - Input size: 256, Tokenized size: 256\n",
      "Chunk 585 - Input size: 256, Tokenized size: 256\n",
      "Chunk 586 - Input size: 256, Tokenized size: 256\n",
      "Chunk 587 - Input size: 256, Tokenized size: 256\n",
      "Chunk 588 - Input size: 256, Tokenized size: 256\n",
      "Chunk 589 - Input size: 256, Tokenized size: 256\n",
      "Chunk 590 - Input size: 256, Tokenized size: 256\n",
      "Chunk 591 - Input size: 256, Tokenized size: 256\n",
      "Chunk 592 - Input size: 256, Tokenized size: 256\n",
      "Chunk 593 - Input size: 256, Tokenized size: 256\n",
      "Chunk 594 - Input size: 256, Tokenized size: 256\n",
      "Chunk 595 - Input size: 256, Tokenized size: 256\n",
      "Chunk 596 - Input size: 256, Tokenized size: 256\n",
      "Chunk 597 - Input size: 256, Tokenized size: 256\n",
      "Chunk 598 - Input size: 256, Tokenized size: 256\n",
      "Chunk 599 - Input size: 256, Tokenized size: 256\n",
      "Chunk 600 - Input size: 256, Tokenized size: 256\n",
      "Chunk 601 - Input size: 256, Tokenized size: 256\n",
      "Chunk 602 - Input size: 256, Tokenized size: 256\n",
      "Chunk 603 - Input size: 256, Tokenized size: 256\n",
      "Chunk 604 - Input size: 256, Tokenized size: 256\n",
      "Chunk 605 - Input size: 256, Tokenized size: 256\n",
      "Chunk 606 - Input size: 256, Tokenized size: 256\n",
      "Chunk 607 - Input size: 256, Tokenized size: 256\n",
      "Chunk 608 - Input size: 256, Tokenized size: 256\n",
      "Chunk 609 - Input size: 256, Tokenized size: 256\n",
      "Chunk 610 - Input size: 256, Tokenized size: 256\n",
      "Chunk 611 - Input size: 256, Tokenized size: 256\n",
      "Chunk 612 - Input size: 256, Tokenized size: 256\n",
      "Chunk 613 - Input size: 256, Tokenized size: 256\n",
      "Chunk 614 - Input size: 256, Tokenized size: 256\n",
      "Chunk 615 - Input size: 256, Tokenized size: 256\n",
      "Chunk 616 - Input size: 256, Tokenized size: 256\n",
      "Chunk 617 - Input size: 256, Tokenized size: 256\n",
      "Chunk 618 - Input size: 256, Tokenized size: 256\n",
      "Chunk 619 - Input size: 256, Tokenized size: 256\n",
      "Chunk 620 - Input size: 256, Tokenized size: 256\n",
      "Chunk 621 - Input size: 256, Tokenized size: 256\n",
      "Chunk 622 - Input size: 256, Tokenized size: 256\n",
      "Chunk 623 - Input size: 256, Tokenized size: 256\n",
      "Chunk 624 - Input size: 256, Tokenized size: 256\n",
      "Chunk 625 - Input size: 256, Tokenized size: 256\n",
      "Chunk 626 - Input size: 256, Tokenized size: 256\n",
      "Chunk 627 - Input size: 256, Tokenized size: 256\n",
      "Chunk 628 - Input size: 256, Tokenized size: 256\n",
      "Chunk 629 - Input size: 256, Tokenized size: 256\n",
      "Chunk 630 - Input size: 256, Tokenized size: 256\n",
      "Chunk 631 - Input size: 256, Tokenized size: 256\n",
      "Chunk 632 - Input size: 256, Tokenized size: 256\n",
      "Chunk 633 - Input size: 256, Tokenized size: 256\n",
      "Chunk 634 - Input size: 256, Tokenized size: 256\n",
      "Chunk 635 - Input size: 256, Tokenized size: 256\n",
      "Chunk 636 - Input size: 256, Tokenized size: 256\n",
      "Chunk 637 - Input size: 256, Tokenized size: 256\n",
      "Chunk 638 - Input size: 256, Tokenized size: 256\n",
      "Chunk 639 - Input size: 256, Tokenized size: 256\n",
      "Chunk 640 - Input size: 256, Tokenized size: 256\n",
      "Chunk 641 - Input size: 256, Tokenized size: 256\n",
      "Chunk 642 - Input size: 256, Tokenized size: 256\n",
      "Chunk 643 - Input size: 256, Tokenized size: 256\n",
      "Chunk 644 - Input size: 256, Tokenized size: 256\n",
      "Chunk 645 - Input size: 256, Tokenized size: 256\n",
      "Chunk 646 - Input size: 256, Tokenized size: 256\n",
      "Chunk 647 - Input size: 256, Tokenized size: 256\n",
      "Chunk 648 - Input size: 256, Tokenized size: 256\n",
      "Chunk 649 - Input size: 256, Tokenized size: 256\n",
      "Chunk 650 - Input size: 256, Tokenized size: 256\n",
      "Chunk 651 - Input size: 256, Tokenized size: 256\n",
      "Chunk 652 - Input size: 256, Tokenized size: 256\n",
      "Chunk 653 - Input size: 256, Tokenized size: 256\n",
      "Chunk 654 - Input size: 256, Tokenized size: 256\n",
      "Chunk 655 - Input size: 256, Tokenized size: 256\n",
      "Chunk 656 - Input size: 256, Tokenized size: 256\n",
      "Chunk 657 - Input size: 256, Tokenized size: 256\n",
      "Chunk 658 - Input size: 256, Tokenized size: 256\n",
      "Chunk 659 - Input size: 256, Tokenized size: 256\n",
      "Chunk 660 - Input size: 256, Tokenized size: 256\n",
      "Chunk 661 - Input size: 256, Tokenized size: 256\n",
      "Chunk 662 - Input size: 256, Tokenized size: 256\n",
      "Chunk 663 - Input size: 256, Tokenized size: 256\n",
      "Chunk 664 - Input size: 256, Tokenized size: 256\n",
      "Chunk 665 - Input size: 256, Tokenized size: 256\n",
      "Chunk 666 - Input size: 256, Tokenized size: 256\n",
      "Chunk 667 - Input size: 256, Tokenized size: 256\n",
      "Chunk 668 - Input size: 256, Tokenized size: 256\n",
      "Chunk 669 - Input size: 256, Tokenized size: 256\n",
      "Chunk 670 - Input size: 256, Tokenized size: 256\n",
      "Chunk 671 - Input size: 256, Tokenized size: 256\n",
      "Chunk 672 - Input size: 256, Tokenized size: 256\n",
      "Chunk 673 - Input size: 256, Tokenized size: 256\n",
      "Chunk 674 - Input size: 256, Tokenized size: 256\n",
      "Chunk 675 - Input size: 256, Tokenized size: 256\n",
      "Chunk 676 - Input size: 256, Tokenized size: 256\n",
      "Chunk 677 - Input size: 256, Tokenized size: 256\n",
      "Chunk 678 - Input size: 256, Tokenized size: 256\n",
      "Chunk 679 - Input size: 256, Tokenized size: 256\n",
      "Chunk 680 - Input size: 256, Tokenized size: 256\n",
      "Chunk 681 - Input size: 256, Tokenized size: 256\n",
      "Chunk 682 - Input size: 256, Tokenized size: 256\n",
      "Chunk 683 - Input size: 256, Tokenized size: 256\n",
      "Chunk 684 - Input size: 256, Tokenized size: 256\n",
      "Chunk 685 - Input size: 256, Tokenized size: 256\n",
      "Chunk 686 - Input size: 256, Tokenized size: 256\n",
      "Chunk 687 - Input size: 256, Tokenized size: 256\n",
      "Chunk 688 - Input size: 256, Tokenized size: 256\n",
      "Chunk 689 - Input size: 256, Tokenized size: 256\n",
      "Chunk 690 - Input size: 256, Tokenized size: 256\n",
      "Chunk 691 - Input size: 256, Tokenized size: 256\n",
      "Chunk 692 - Input size: 256, Tokenized size: 256\n",
      "Chunk 693 - Input size: 256, Tokenized size: 256\n",
      "Chunk 694 - Input size: 256, Tokenized size: 256\n",
      "Chunk 695 - Input size: 256, Tokenized size: 256\n",
      "Chunk 696 - Input size: 256, Tokenized size: 256\n",
      "Chunk 697 - Input size: 256, Tokenized size: 256\n",
      "Chunk 698 - Input size: 256, Tokenized size: 256\n",
      "Chunk 699 - Input size: 256, Tokenized size: 256\n",
      "Chunk 700 - Input size: 256, Tokenized size: 256\n",
      "Chunk 701 - Input size: 256, Tokenized size: 256\n",
      "Chunk 702 - Input size: 256, Tokenized size: 256\n",
      "Chunk 703 - Input size: 256, Tokenized size: 256\n",
      "Chunk 704 - Input size: 256, Tokenized size: 256\n",
      "Chunk 705 - Input size: 256, Tokenized size: 256\n",
      "Chunk 706 - Input size: 256, Tokenized size: 256\n",
      "Chunk 707 - Input size: 256, Tokenized size: 256\n",
      "Chunk 708 - Input size: 256, Tokenized size: 256\n",
      "Chunk 709 - Input size: 256, Tokenized size: 256\n",
      "Chunk 710 - Input size: 256, Tokenized size: 256\n",
      "Chunk 711 - Input size: 256, Tokenized size: 256\n",
      "Chunk 712 - Input size: 256, Tokenized size: 256\n",
      "Chunk 713 - Input size: 256, Tokenized size: 256\n",
      "Chunk 714 - Input size: 256, Tokenized size: 256\n",
      "Chunk 715 - Input size: 256, Tokenized size: 256\n",
      "Chunk 716 - Input size: 256, Tokenized size: 256\n",
      "Chunk 717 - Input size: 256, Tokenized size: 256\n",
      "Chunk 718 - Input size: 256, Tokenized size: 256\n",
      "Chunk 719 - Input size: 256, Tokenized size: 256\n",
      "Chunk 720 - Input size: 256, Tokenized size: 256\n",
      "Chunk 721 - Input size: 256, Tokenized size: 256\n",
      "Chunk 722 - Input size: 256, Tokenized size: 256\n",
      "Chunk 723 - Input size: 256, Tokenized size: 256\n",
      "Chunk 724 - Input size: 256, Tokenized size: 256\n",
      "Chunk 725 - Input size: 256, Tokenized size: 256\n",
      "Chunk 726 - Input size: 256, Tokenized size: 256\n",
      "Chunk 727 - Input size: 256, Tokenized size: 256\n",
      "Chunk 728 - Input size: 256, Tokenized size: 256\n",
      "Chunk 729 - Input size: 256, Tokenized size: 256\n",
      "Chunk 730 - Input size: 256, Tokenized size: 256\n",
      "Chunk 731 - Input size: 256, Tokenized size: 256\n",
      "Chunk 732 - Input size: 256, Tokenized size: 256\n",
      "Chunk 733 - Input size: 256, Tokenized size: 256\n",
      "Chunk 734 - Input size: 256, Tokenized size: 256\n",
      "Chunk 735 - Input size: 256, Tokenized size: 256\n",
      "Chunk 736 - Input size: 256, Tokenized size: 256\n",
      "Chunk 737 - Input size: 256, Tokenized size: 256\n",
      "Chunk 738 - Input size: 256, Tokenized size: 256\n",
      "Chunk 739 - Input size: 256, Tokenized size: 256\n",
      "Chunk 740 - Input size: 256, Tokenized size: 256\n",
      "Chunk 741 - Input size: 256, Tokenized size: 256\n",
      "Chunk 742 - Input size: 256, Tokenized size: 256\n",
      "Chunk 743 - Input size: 256, Tokenized size: 256\n",
      "Chunk 744 - Input size: 256, Tokenized size: 256\n",
      "Chunk 745 - Input size: 256, Tokenized size: 256\n",
      "Chunk 746 - Input size: 256, Tokenized size: 256\n",
      "Chunk 747 - Input size: 256, Tokenized size: 256\n",
      "Chunk 748 - Input size: 256, Tokenized size: 256\n",
      "Chunk 749 - Input size: 256, Tokenized size: 256\n",
      "Chunk 750 - Input size: 256, Tokenized size: 256\n",
      "Chunk 751 - Input size: 256, Tokenized size: 256\n",
      "Chunk 752 - Input size: 256, Tokenized size: 256\n",
      "Chunk 753 - Input size: 256, Tokenized size: 256\n",
      "Chunk 754 - Input size: 256, Tokenized size: 256\n",
      "Chunk 755 - Input size: 256, Tokenized size: 256\n",
      "Chunk 756 - Input size: 256, Tokenized size: 256\n",
      "Chunk 757 - Input size: 256, Tokenized size: 256\n",
      "Chunk 758 - Input size: 256, Tokenized size: 256\n",
      "Chunk 759 - Input size: 256, Tokenized size: 256\n",
      "Chunk 760 - Input size: 256, Tokenized size: 256\n",
      "Chunk 761 - Input size: 256, Tokenized size: 256\n",
      "Chunk 762 - Input size: 256, Tokenized size: 256\n",
      "Chunk 763 - Input size: 256, Tokenized size: 256\n",
      "Chunk 764 - Input size: 256, Tokenized size: 256\n",
      "Chunk 765 - Input size: 256, Tokenized size: 256\n",
      "Chunk 766 - Input size: 256, Tokenized size: 256\n",
      "Chunk 767 - Input size: 256, Tokenized size: 256\n",
      "Chunk 768 - Input size: 256, Tokenized size: 256\n",
      "Chunk 769 - Input size: 256, Tokenized size: 256\n",
      "Chunk 770 - Input size: 256, Tokenized size: 256\n",
      "Chunk 771 - Input size: 256, Tokenized size: 256\n",
      "Chunk 772 - Input size: 256, Tokenized size: 256\n",
      "Chunk 773 - Input size: 256, Tokenized size: 256\n",
      "Chunk 774 - Input size: 256, Tokenized size: 256\n",
      "Chunk 775 - Input size: 256, Tokenized size: 256\n",
      "Chunk 776 - Input size: 256, Tokenized size: 256\n",
      "Chunk 777 - Input size: 256, Tokenized size: 256\n",
      "Chunk 778 - Input size: 256, Tokenized size: 256\n",
      "Chunk 779 - Input size: 256, Tokenized size: 256\n",
      "Chunk 780 - Input size: 256, Tokenized size: 256\n",
      "Chunk 781 - Input size: 256, Tokenized size: 256\n",
      "Chunk 782 - Input size: 256, Tokenized size: 256\n",
      "Chunk 783 - Input size: 256, Tokenized size: 256\n",
      "Chunk 784 - Input size: 256, Tokenized size: 256\n",
      "Chunk 785 - Input size: 256, Tokenized size: 256\n",
      "Chunk 786 - Input size: 256, Tokenized size: 256\n",
      "Chunk 787 - Input size: 256, Tokenized size: 256\n",
      "Chunk 788 - Input size: 256, Tokenized size: 256\n",
      "Chunk 789 - Input size: 256, Tokenized size: 256\n",
      "Chunk 790 - Input size: 256, Tokenized size: 256\n",
      "Chunk 791 - Input size: 256, Tokenized size: 256\n",
      "Chunk 792 - Input size: 256, Tokenized size: 256\n",
      "Chunk 793 - Input size: 256, Tokenized size: 256\n",
      "Chunk 794 - Input size: 256, Tokenized size: 256\n",
      "Chunk 795 - Input size: 256, Tokenized size: 256\n",
      "Chunk 796 - Input size: 256, Tokenized size: 256\n",
      "Chunk 797 - Input size: 256, Tokenized size: 256\n",
      "Chunk 798 - Input size: 256, Tokenized size: 256\n",
      "Chunk 799 - Input size: 256, Tokenized size: 256\n",
      "Chunk 800 - Input size: 256, Tokenized size: 256\n",
      "Chunk 801 - Input size: 256, Tokenized size: 256\n",
      "Chunk 802 - Input size: 256, Tokenized size: 256\n",
      "Chunk 803 - Input size: 256, Tokenized size: 256\n",
      "Chunk 804 - Input size: 256, Tokenized size: 256\n",
      "Chunk 805 - Input size: 256, Tokenized size: 256\n",
      "Chunk 806 - Input size: 256, Tokenized size: 256\n",
      "Chunk 807 - Input size: 256, Tokenized size: 256\n",
      "Chunk 808 - Input size: 256, Tokenized size: 256\n",
      "Chunk 809 - Input size: 256, Tokenized size: 256\n",
      "Chunk 810 - Input size: 256, Tokenized size: 256\n",
      "Chunk 811 - Input size: 256, Tokenized size: 256\n",
      "Chunk 812 - Input size: 256, Tokenized size: 256\n",
      "Chunk 813 - Input size: 256, Tokenized size: 256\n",
      "Chunk 814 - Input size: 256, Tokenized size: 256\n",
      "Chunk 815 - Input size: 256, Tokenized size: 256\n",
      "Chunk 816 - Input size: 256, Tokenized size: 256\n",
      "Chunk 817 - Input size: 256, Tokenized size: 256\n",
      "Chunk 818 - Input size: 256, Tokenized size: 256\n",
      "Chunk 819 - Input size: 256, Tokenized size: 256\n",
      "Chunk 820 - Input size: 256, Tokenized size: 256\n",
      "Chunk 821 - Input size: 256, Tokenized size: 256\n",
      "Chunk 822 - Input size: 256, Tokenized size: 256\n",
      "Chunk 823 - Input size: 256, Tokenized size: 256\n",
      "Chunk 824 - Input size: 256, Tokenized size: 256\n",
      "Chunk 825 - Input size: 256, Tokenized size: 256\n",
      "Chunk 826 - Input size: 256, Tokenized size: 256\n",
      "Chunk 827 - Input size: 256, Tokenized size: 256\n",
      "Chunk 828 - Input size: 256, Tokenized size: 256\n",
      "Chunk 829 - Input size: 256, Tokenized size: 256\n",
      "Chunk 830 - Input size: 256, Tokenized size: 256\n",
      "Chunk 831 - Input size: 256, Tokenized size: 256\n",
      "Chunk 832 - Input size: 256, Tokenized size: 256\n",
      "Chunk 833 - Input size: 256, Tokenized size: 256\n",
      "Chunk 834 - Input size: 256, Tokenized size: 256\n",
      "Chunk 835 - Input size: 256, Tokenized size: 256\n",
      "Chunk 836 - Input size: 256, Tokenized size: 256\n",
      "Chunk 837 - Input size: 256, Tokenized size: 256\n",
      "Chunk 838 - Input size: 256, Tokenized size: 256\n",
      "Chunk 839 - Input size: 256, Tokenized size: 256\n",
      "Chunk 840 - Input size: 256, Tokenized size: 256\n",
      "Chunk 841 - Input size: 256, Tokenized size: 256\n",
      "Chunk 842 - Input size: 256, Tokenized size: 256\n",
      "Chunk 843 - Input size: 256, Tokenized size: 256\n",
      "Chunk 844 - Input size: 256, Tokenized size: 256\n",
      "Chunk 845 - Input size: 256, Tokenized size: 256\n",
      "Chunk 846 - Input size: 256, Tokenized size: 256\n",
      "Chunk 847 - Input size: 256, Tokenized size: 256\n",
      "Chunk 848 - Input size: 256, Tokenized size: 256\n",
      "Chunk 849 - Input size: 256, Tokenized size: 256\n",
      "Chunk 850 - Input size: 256, Tokenized size: 256\n",
      "Chunk 851 - Input size: 256, Tokenized size: 256\n",
      "Chunk 852 - Input size: 256, Tokenized size: 256\n",
      "Chunk 853 - Input size: 256, Tokenized size: 256\n",
      "Chunk 854 - Input size: 256, Tokenized size: 256\n",
      "Chunk 855 - Input size: 256, Tokenized size: 256\n",
      "Chunk 856 - Input size: 256, Tokenized size: 256\n",
      "Chunk 857 - Input size: 256, Tokenized size: 256\n",
      "Chunk 858 - Input size: 256, Tokenized size: 256\n",
      "Chunk 859 - Input size: 256, Tokenized size: 256\n",
      "Chunk 860 - Input size: 256, Tokenized size: 256\n",
      "Chunk 861 - Input size: 256, Tokenized size: 256\n",
      "Chunk 862 - Input size: 256, Tokenized size: 256\n",
      "Chunk 863 - Input size: 256, Tokenized size: 256\n",
      "Chunk 864 - Input size: 256, Tokenized size: 256\n",
      "Chunk 865 - Input size: 256, Tokenized size: 256\n",
      "Chunk 866 - Input size: 256, Tokenized size: 256\n",
      "Chunk 867 - Input size: 256, Tokenized size: 256\n",
      "Chunk 868 - Input size: 256, Tokenized size: 256\n",
      "Chunk 869 - Input size: 256, Tokenized size: 256\n",
      "Chunk 870 - Input size: 256, Tokenized size: 256\n",
      "Chunk 871 - Input size: 256, Tokenized size: 256\n",
      "Chunk 872 - Input size: 256, Tokenized size: 256\n",
      "Chunk 0 - Input size: 256, Tokenized size: 256\n",
      "Chunk 1 - Input size: 256, Tokenized size: 256\n",
      "Chunk 2 - Input size: 256, Tokenized size: 256\n",
      "Chunk 3 - Input size: 256, Tokenized size: 256\n",
      "Chunk 4 - Input size: 256, Tokenized size: 256\n",
      "Chunk 5 - Input size: 256, Tokenized size: 256\n",
      "Chunk 6 - Input size: 256, Tokenized size: 256\n",
      "Chunk 7 - Input size: 256, Tokenized size: 256\n",
      "Chunk 8 - Input size: 256, Tokenized size: 256\n",
      "Chunk 9 - Input size: 256, Tokenized size: 256\n",
      "Chunk 10 - Input size: 256, Tokenized size: 256\n",
      "Chunk 11 - Input size: 256, Tokenized size: 256\n",
      "Chunk 12 - Input size: 256, Tokenized size: 256\n",
      "Chunk 13 - Input size: 256, Tokenized size: 256\n",
      "Chunk 14 - Input size: 256, Tokenized size: 256\n",
      "Chunk 15 - Input size: 256, Tokenized size: 256\n",
      "Chunk 16 - Input size: 256, Tokenized size: 256\n",
      "Chunk 17 - Input size: 256, Tokenized size: 256\n",
      "Chunk 18 - Input size: 256, Tokenized size: 256\n",
      "Chunk 19 - Input size: 256, Tokenized size: 256\n",
      "Chunk 20 - Input size: 256, Tokenized size: 256\n",
      "Chunk 21 - Input size: 256, Tokenized size: 256\n",
      "Chunk 22 - Input size: 256, Tokenized size: 256\n",
      "Chunk 23 - Input size: 256, Tokenized size: 256\n",
      "Chunk 24 - Input size: 256, Tokenized size: 256\n",
      "Chunk 25 - Input size: 256, Tokenized size: 256\n",
      "Chunk 26 - Input size: 256, Tokenized size: 256\n",
      "Chunk 27 - Input size: 256, Tokenized size: 256\n",
      "Chunk 28 - Input size: 256, Tokenized size: 256\n",
      "Chunk 29 - Input size: 256, Tokenized size: 256\n",
      "Chunk 30 - Input size: 256, Tokenized size: 256\n",
      "Chunk 0 - Input size: 256, Tokenized size: 256\n",
      "Chunk 1 - Input size: 256, Tokenized size: 256\n",
      "Chunk 2 - Input size: 256, Tokenized size: 256\n",
      "Chunk 3 - Input size: 256, Tokenized size: 256\n",
      "Chunk 4 - Input size: 256, Tokenized size: 256\n",
      "Chunk 5 - Input size: 256, Tokenized size: 256\n",
      "Chunk 6 - Input size: 256, Tokenized size: 256\n",
      "Chunk 7 - Input size: 256, Tokenized size: 256\n",
      "Chunk 8 - Input size: 256, Tokenized size: 256\n",
      "Chunk 9 - Input size: 256, Tokenized size: 256\n",
      "Chunk 10 - Input size: 256, Tokenized size: 256\n",
      "Chunk 11 - Input size: 256, Tokenized size: 256\n",
      "Chunk 12 - Input size: 256, Tokenized size: 256\n",
      "Chunk 13 - Input size: 256, Tokenized size: 256\n",
      "Chunk 14 - Input size: 256, Tokenized size: 256\n",
      "Chunk 15 - Input size: 256, Tokenized size: 256\n",
      "Chunk 16 - Input size: 256, Tokenized size: 256\n",
      "Chunk 17 - Input size: 256, Tokenized size: 256\n",
      "Chunk 18 - Input size: 256, Tokenized size: 256\n",
      "Chunk 19 - Input size: 256, Tokenized size: 256\n",
      "Chunk 20 - Input size: 256, Tokenized size: 256\n",
      "Chunk 21 - Input size: 256, Tokenized size: 256\n",
      "Chunk 22 - Input size: 256, Tokenized size: 256\n",
      "Chunk 23 - Input size: 256, Tokenized size: 256\n",
      "Chunk 24 - Input size: 256, Tokenized size: 256\n",
      "Chunk 25 - Input size: 256, Tokenized size: 256\n",
      "Chunk 26 - Input size: 256, Tokenized size: 256\n",
      "Chunk 27 - Input size: 256, Tokenized size: 256\n",
      "Chunk 28 - Input size: 256, Tokenized size: 256\n",
      "Chunk 29 - Input size: 256, Tokenized size: 256\n",
      "Chunk 30 - Input size: 256, Tokenized size: 256\n",
      "Chunk 31 - Input size: 256, Tokenized size: 256\n",
      "Chunk 32 - Input size: 256, Tokenized size: 256\n",
      "Chunk 33 - Input size: 256, Tokenized size: 256\n",
      "Chunk 34 - Input size: 256, Tokenized size: 256\n",
      "Chunk 35 - Input size: 256, Tokenized size: 256\n",
      "Chunk 36 - Input size: 256, Tokenized size: 256\n",
      "Chunk 37 - Input size: 256, Tokenized size: 256\n",
      "Chunk 38 - Input size: 256, Tokenized size: 256\n",
      "Chunk 39 - Input size: 256, Tokenized size: 256\n",
      "Chunk 40 - Input size: 256, Tokenized size: 256\n",
      "Chunk 41 - Input size: 256, Tokenized size: 256\n",
      "Chunk 42 - Input size: 256, Tokenized size: 256\n",
      "Chunk 43 - Input size: 256, Tokenized size: 256\n",
      "Chunk 44 - Input size: 256, Tokenized size: 256\n",
      "Chunk 45 - Input size: 256, Tokenized size: 256\n",
      "Chunk 46 - Input size: 256, Tokenized size: 256\n",
      "Chunk 47 - Input size: 256, Tokenized size: 256\n",
      "Chunk 48 - Input size: 256, Tokenized size: 256\n",
      "Chunk 49 - Input size: 256, Tokenized size: 256\n",
      "Chunk 50 - Input size: 256, Tokenized size: 256\n",
      "Chunk 51 - Input size: 256, Tokenized size: 256\n",
      "Chunk 52 - Input size: 256, Tokenized size: 256\n",
      "Chunk 53 - Input size: 256, Tokenized size: 256\n",
      "Chunk 54 - Input size: 256, Tokenized size: 256\n",
      "Chunk 55 - Input size: 256, Tokenized size: 256\n",
      "Chunk 56 - Input size: 256, Tokenized size: 256\n",
      "Chunk 57 - Input size: 256, Tokenized size: 256\n",
      "Chunk 58 - Input size: 256, Tokenized size: 256\n",
      "Chunk 59 - Input size: 256, Tokenized size: 256\n",
      "Chunk 60 - Input size: 256, Tokenized size: 256\n",
      "Chunk 61 - Input size: 256, Tokenized size: 256\n",
      "Chunk 62 - Input size: 256, Tokenized size: 256\n",
      "Chunk 63 - Input size: 256, Tokenized size: 256\n",
      "Chunk 64 - Input size: 256, Tokenized size: 256\n",
      "Chunk 65 - Input size: 256, Tokenized size: 256\n",
      "Chunk 66 - Input size: 256, Tokenized size: 256\n",
      "Chunk 67 - Input size: 256, Tokenized size: 256\n",
      "Chunk 68 - Input size: 256, Tokenized size: 256\n",
      "Chunk 69 - Input size: 256, Tokenized size: 256\n",
      "Chunk 70 - Input size: 256, Tokenized size: 256\n",
      "Chunk 71 - Input size: 256, Tokenized size: 256\n",
      "Chunk 72 - Input size: 256, Tokenized size: 256\n",
      "Chunk 73 - Input size: 256, Tokenized size: 256\n",
      "Chunk 74 - Input size: 256, Tokenized size: 256\n",
      "Chunk 75 - Input size: 256, Tokenized size: 256\n",
      "Chunk 76 - Input size: 256, Tokenized size: 256\n",
      "Chunk 77 - Input size: 256, Tokenized size: 256\n",
      "Chunk 78 - Input size: 256, Tokenized size: 256\n",
      "Chunk 79 - Input size: 256, Tokenized size: 256\n",
      "Chunk 80 - Input size: 256, Tokenized size: 256\n",
      "Chunk 81 - Input size: 256, Tokenized size: 256\n",
      "Chunk 82 - Input size: 256, Tokenized size: 256\n",
      "Chunk 83 - Input size: 256, Tokenized size: 256\n",
      "Chunk 84 - Input size: 256, Tokenized size: 256\n",
      "Chunk 85 - Input size: 256, Tokenized size: 256\n",
      "Chunk 86 - Input size: 256, Tokenized size: 256\n",
      "Chunk 87 - Input size: 256, Tokenized size: 256\n",
      "Chunk 88 - Input size: 256, Tokenized size: 256\n",
      "Chunk 89 - Input size: 256, Tokenized size: 256\n",
      "Chunk 90 - Input size: 256, Tokenized size: 256\n",
      "Chunk 91 - Input size: 256, Tokenized size: 256\n",
      "Chunk 92 - Input size: 256, Tokenized size: 256\n",
      "Chunk 93 - Input size: 256, Tokenized size: 256\n",
      "Chunk 94 - Input size: 256, Tokenized size: 256\n",
      "Chunk 95 - Input size: 256, Tokenized size: 256\n",
      "Chunk 96 - Input size: 256, Tokenized size: 256\n",
      "Chunk 97 - Input size: 256, Tokenized size: 256\n",
      "Chunk 98 - Input size: 256, Tokenized size: 256\n",
      "Chunk 99 - Input size: 256, Tokenized size: 256\n",
      "Chunk 100 - Input size: 256, Tokenized size: 256\n",
      "Chunk 101 - Input size: 256, Tokenized size: 256\n",
      "Chunk 102 - Input size: 256, Tokenized size: 256\n",
      "Chunk 103 - Input size: 256, Tokenized size: 256\n",
      "Chunk 104 - Input size: 256, Tokenized size: 256\n",
      "Chunk 105 - Input size: 256, Tokenized size: 256\n",
      "Chunk 106 - Input size: 256, Tokenized size: 256\n",
      "Chunk 107 - Input size: 256, Tokenized size: 256\n",
      "Chunk 108 - Input size: 256, Tokenized size: 256\n",
      "Chunk 109 - Input size: 256, Tokenized size: 256\n",
      "Chunk 110 - Input size: 256, Tokenized size: 256\n",
      "Chunk 111 - Input size: 256, Tokenized size: 256\n",
      "Chunk 112 - Input size: 256, Tokenized size: 256\n",
      "Chunk 113 - Input size: 256, Tokenized size: 256\n",
      "Chunk 114 - Input size: 256, Tokenized size: 256\n",
      "Chunk 115 - Input size: 256, Tokenized size: 256\n",
      "Chunk 116 - Input size: 256, Tokenized size: 256\n",
      "Chunk 117 - Input size: 256, Tokenized size: 256\n",
      "Chunk 118 - Input size: 256, Tokenized size: 256\n",
      "Chunk 119 - Input size: 256, Tokenized size: 256\n",
      "Chunk 120 - Input size: 256, Tokenized size: 256\n",
      "Chunk 121 - Input size: 256, Tokenized size: 256\n",
      "Chunk 122 - Input size: 256, Tokenized size: 256\n",
      "Chunk 123 - Input size: 256, Tokenized size: 256\n",
      "Chunk 124 - Input size: 256, Tokenized size: 256\n",
      "Chunk 125 - Input size: 256, Tokenized size: 256\n",
      "Chunk 126 - Input size: 256, Tokenized size: 256\n",
      "Chunk 127 - Input size: 256, Tokenized size: 256\n",
      "Chunk 128 - Input size: 256, Tokenized size: 256\n",
      "Chunk 129 - Input size: 256, Tokenized size: 256\n",
      "Chunk 130 - Input size: 256, Tokenized size: 256\n",
      "Chunk 131 - Input size: 256, Tokenized size: 256\n",
      "Chunk 132 - Input size: 256, Tokenized size: 256\n",
      "Chunk 133 - Input size: 256, Tokenized size: 256\n",
      "Chunk 134 - Input size: 256, Tokenized size: 256\n",
      "Chunk 135 - Input size: 256, Tokenized size: 256\n",
      "Chunk 136 - Input size: 256, Tokenized size: 256\n",
      "Chunk 137 - Input size: 256, Tokenized size: 256\n",
      "Chunk 138 - Input size: 256, Tokenized size: 256\n",
      "Chunk 139 - Input size: 256, Tokenized size: 256\n",
      "Chunk 140 - Input size: 256, Tokenized size: 256\n",
      "Chunk 141 - Input size: 256, Tokenized size: 256\n",
      "Chunk 142 - Input size: 256, Tokenized size: 256\n",
      "Chunk 143 - Input size: 256, Tokenized size: 256\n",
      "Chunk 144 - Input size: 256, Tokenized size: 256\n",
      "Chunk 145 - Input size: 256, Tokenized size: 256\n",
      "Chunk 146 - Input size: 256, Tokenized size: 256\n",
      "Chunk 147 - Input size: 256, Tokenized size: 256\n",
      "Chunk 148 - Input size: 256, Tokenized size: 256\n",
      "Chunk 149 - Input size: 256, Tokenized size: 256\n",
      "Chunk 150 - Input size: 256, Tokenized size: 256\n",
      "Chunk 151 - Input size: 256, Tokenized size: 256\n",
      "Chunk 152 - Input size: 256, Tokenized size: 256\n",
      "Chunk 153 - Input size: 256, Tokenized size: 256\n",
      "Chunk 154 - Input size: 256, Tokenized size: 256\n",
      "Chunk 155 - Input size: 256, Tokenized size: 256\n",
      "Chunk 156 - Input size: 256, Tokenized size: 256\n",
      "Chunk 157 - Input size: 256, Tokenized size: 256\n",
      "Chunk 158 - Input size: 256, Tokenized size: 256\n",
      "Chunk 159 - Input size: 256, Tokenized size: 256\n",
      "Chunk 160 - Input size: 256, Tokenized size: 256\n",
      "Chunk 161 - Input size: 256, Tokenized size: 256\n",
      "Chunk 162 - Input size: 256, Tokenized size: 256\n",
      "Chunk 163 - Input size: 256, Tokenized size: 256\n",
      "Chunk 164 - Input size: 256, Tokenized size: 256\n",
      "Chunk 165 - Input size: 256, Tokenized size: 256\n",
      "Chunk 166 - Input size: 256, Tokenized size: 256\n",
      "Chunk 167 - Input size: 256, Tokenized size: 256\n",
      "Chunk 168 - Input size: 256, Tokenized size: 256\n",
      "Chunk 169 - Input size: 256, Tokenized size: 256\n",
      "Chunk 170 - Input size: 256, Tokenized size: 256\n",
      "Chunk 171 - Input size: 256, Tokenized size: 256\n",
      "Chunk 172 - Input size: 256, Tokenized size: 256\n",
      "Chunk 173 - Input size: 256, Tokenized size: 256\n",
      "Chunk 174 - Input size: 256, Tokenized size: 256\n",
      "Chunk 175 - Input size: 256, Tokenized size: 256\n",
      "Chunk 176 - Input size: 256, Tokenized size: 256\n",
      "Chunk 177 - Input size: 256, Tokenized size: 256\n",
      "Chunk 178 - Input size: 256, Tokenized size: 256\n",
      "Chunk 179 - Input size: 256, Tokenized size: 256\n",
      "Chunk 180 - Input size: 256, Tokenized size: 256\n",
      "Chunk 181 - Input size: 256, Tokenized size: 256\n",
      "Chunk 182 - Input size: 256, Tokenized size: 256\n",
      "Chunk 183 - Input size: 256, Tokenized size: 256\n",
      "Chunk 184 - Input size: 256, Tokenized size: 256\n",
      "Chunk 185 - Input size: 256, Tokenized size: 256\n",
      "Chunk 186 - Input size: 256, Tokenized size: 256\n",
      "Chunk 187 - Input size: 256, Tokenized size: 256\n",
      "Chunk 188 - Input size: 256, Tokenized size: 256\n",
      "Chunk 189 - Input size: 256, Tokenized size: 256\n",
      "Chunk 190 - Input size: 256, Tokenized size: 256\n",
      "Chunk 191 - Input size: 256, Tokenized size: 256\n",
      "Chunk 192 - Input size: 256, Tokenized size: 256\n",
      "Chunk 193 - Input size: 256, Tokenized size: 256\n",
      "Chunk 194 - Input size: 256, Tokenized size: 256\n",
      "Chunk 195 - Input size: 256, Tokenized size: 256\n",
      "Chunk 196 - Input size: 256, Tokenized size: 256\n",
      "Chunk 197 - Input size: 256, Tokenized size: 256\n",
      "Chunk 198 - Input size: 256, Tokenized size: 256\n",
      "Chunk 199 - Input size: 256, Tokenized size: 256\n",
      "Chunk 200 - Input size: 256, Tokenized size: 256\n",
      "Chunk 201 - Input size: 256, Tokenized size: 256\n",
      "Chunk 202 - Input size: 256, Tokenized size: 256\n",
      "Chunk 203 - Input size: 256, Tokenized size: 256\n",
      "Chunk 204 - Input size: 256, Tokenized size: 256\n",
      "Chunk 205 - Input size: 256, Tokenized size: 256\n",
      "Chunk 206 - Input size: 256, Tokenized size: 256\n",
      "Chunk 207 - Input size: 256, Tokenized size: 256\n",
      "Chunk 208 - Input size: 256, Tokenized size: 256\n",
      "Chunk 209 - Input size: 256, Tokenized size: 256\n",
      "Chunk 210 - Input size: 256, Tokenized size: 256\n",
      "Chunk 211 - Input size: 256, Tokenized size: 256\n",
      "Chunk 212 - Input size: 256, Tokenized size: 256\n",
      "Chunk 213 - Input size: 256, Tokenized size: 256\n",
      "Chunk 214 - Input size: 256, Tokenized size: 256\n",
      "Chunk 215 - Input size: 256, Tokenized size: 256\n",
      "Chunk 216 - Input size: 256, Tokenized size: 256\n",
      "Chunk 217 - Input size: 256, Tokenized size: 256\n",
      "Chunk 218 - Input size: 256, Tokenized size: 256\n",
      "Chunk 219 - Input size: 256, Tokenized size: 256\n",
      "Chunk 220 - Input size: 256, Tokenized size: 256\n",
      "Chunk 221 - Input size: 256, Tokenized size: 256\n",
      "Chunk 222 - Input size: 256, Tokenized size: 256\n",
      "Chunk 223 - Input size: 256, Tokenized size: 256\n",
      "Chunk 224 - Input size: 256, Tokenized size: 256\n",
      "Chunk 225 - Input size: 256, Tokenized size: 256\n",
      "Chunk 226 - Input size: 256, Tokenized size: 256\n",
      "Chunk 227 - Input size: 256, Tokenized size: 256\n",
      "Chunk 228 - Input size: 256, Tokenized size: 256\n",
      "Chunk 229 - Input size: 256, Tokenized size: 256\n",
      "Chunk 230 - Input size: 256, Tokenized size: 256\n",
      "Chunk 231 - Input size: 256, Tokenized size: 256\n",
      "Chunk 232 - Input size: 256, Tokenized size: 256\n",
      "Chunk 233 - Input size: 256, Tokenized size: 256\n",
      "Chunk 234 - Input size: 256, Tokenized size: 256\n",
      "Chunk 235 - Input size: 256, Tokenized size: 256\n",
      "Chunk 236 - Input size: 256, Tokenized size: 256\n",
      "Chunk 237 - Input size: 256, Tokenized size: 256\n",
      "Chunk 238 - Input size: 256, Tokenized size: 256\n",
      "Chunk 239 - Input size: 256, Tokenized size: 256\n",
      "Chunk 240 - Input size: 256, Tokenized size: 256\n",
      "Chunk 241 - Input size: 256, Tokenized size: 256\n",
      "Chunk 242 - Input size: 256, Tokenized size: 256\n",
      "Chunk 243 - Input size: 256, Tokenized size: 256\n",
      "Chunk 244 - Input size: 256, Tokenized size: 256\n",
      "Chunk 245 - Input size: 256, Tokenized size: 256\n",
      "Chunk 246 - Input size: 256, Tokenized size: 256\n",
      "Chunk 247 - Input size: 256, Tokenized size: 256\n",
      "Chunk 248 - Input size: 256, Tokenized size: 256\n"
     ]
    }
   ],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=192):\n",
    "    all_ids = []  # List to store token IDs\n",
    "    all_masks = []  # List to store attention masks\n",
    "\n",
    "    original_rows = len(texts)\n",
    "    num_full_chunks = len(texts) // chunk_size\n",
    "    \n",
    "    \n",
    "    processed_rows = 0\n",
    "    # Process texts in chunks\n",
    "    for i in range(0, num_full_chunks*chunk_size, chunk_size):\n",
    "        text_chunk = texts[i:i + chunk_size].tolist()  # Get a chunk of texts\n",
    "        \n",
    "        # Tokenize with padding and truncation explicitly set\n",
    "        encs = tokenizer(text_chunk, truncation=True, padding='max_length', max_length=maxlen, return_tensors='np')\n",
    "\n",
    "        chunk_size_actual = len(text_chunk)\n",
    "        chunk_output_size = encs['input_ids'].shape[0]\n",
    "        \n",
    "        print(f\"Chunk {i // chunk_size} - Input size: {chunk_size_actual}, Tokenized size: {chunk_output_size}\")\n",
    "\n",
    "        processed_rows += chunk_output_size  # Track processed rows\n",
    "\n",
    "\n",
    "        # Extract `input_ids` and `attention_mask`\n",
    "        all_ids.extend(encs['input_ids'])\n",
    "        all_masks.extend(encs['attention_mask'])\n",
    "\n",
    "    # Convert to NumPy arrays for easier handling\n",
    "    return np.array(all_ids), np.array(all_masks)\n",
    "\n",
    "\n",
    "#tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Example Usage\n",
    "x_train,train_mask = fast_encode(train_data.comment_text.astype(str), tokenizer, maxlen=192)\n",
    "x_valid,valid_mask = fast_encode(valid_data.comment_text.astype(str), tokenizer, maxlen=192)\n",
    "x_test,test_mask = fast_encode(test_data.content.astype(str), tokenizer, maxlen=192)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223488, 192)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data size: 223549\n",
      "Encoded x_train size: 223488\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original train data size: {len(train_data.comment_text)}\")\n",
    "print(f\"Encoded x_train size: {len(x_train)}\")  # Should match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO=tf.data.experimental.AUTOTUNE\n",
    "\n",
    "EPOCHS=3\n",
    "BATCH_SIZE=256\n",
    "MAX_LEN=192\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train inputs\n",
    "train_inputs = {\n",
    "    'input_ids': x_train,\n",
    "    'attention_mask': train_mask\n",
    "}\n",
    "\n",
    "# Validation inputs\n",
    "valid_inputs = {\n",
    "    'input_ids': x_valid,\n",
    "    'attention_mask': valid_mask\n",
    "}\n",
    "\n",
    "# Test inputs\n",
    "test_inputs = {\n",
    "    'input_ids': x_test,\n",
    "    'attention_mask': test_mask\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data['toxic'].values\n",
    "\n",
    "y_train_clipped=y_train[:x_train.shape[0]]\n",
    "\n",
    "\n",
    "y_valid=valid_data['toxic'].values\n",
    "\n",
    "y_valid_clipped=y_valid[:x_valid.shape[0]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=(tf.data.Dataset.from_tensor_slices((train_inputs,y_train_clipped)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n",
    "\n",
    "valid_dataset=(tf.data.Dataset.from_tensor_slices((valid_inputs,y_valid_clipped)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=(tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def build_model(transformer,max_len=192):\n",
    "# #     # input_word_ids=Input(shape=(max_len,),dtype=tf.int32,name='input_word_ids')\n",
    "# #     # sequence_output=transformer(input_word_ids)[0]\n",
    "# #     input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_word_ids')\n",
    "# #     attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "# #     sequence_output = transformer(input_ids=input_word_ids, attention_mask=attention_mask)[0]\n",
    "# #     cls_token=sequence_output[:,0,:]\n",
    "# #     out=Dense(1,activation='sigmoid')(cls_token)\n",
    "\n",
    "# #     model=Model(inputs=[input_word_ids,attention_mask],outputs=out)\n",
    "# #     model.compile(Adam(lr=1e-5),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# #     return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def build_model(transformer_func, max_len=192):\n",
    "#     # Input layers\n",
    "#     input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name='input_word_ids')\n",
    "#     attention_mask = Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "#     # Pass inputs to the transformer\n",
    "#     # sequence_output = transformer(input_ids=input_word_ids, attention_mask=attention_mask)[0]\n",
    "#     print(f\"Input Word IDs: {input_word_ids.shape}\")\n",
    "#     print(f\"Attention Mask: {attention_mask.shape}\")\n",
    "#     transformer_output = transformer(input_ids=input_word_ids, attention_mask=attention_mask)\n",
    "#     print(f\"Transformer Output: {transformer_output['last_hidden_state'].shape}\")\n",
    " \n",
    "    \n",
    "#     # transformer_output = transformer(input_ids=input_word_ids, attention_mask=attention_mask)\n",
    "#     # print(transformer_output)\n",
    "#     sequence_output = transformer_output.last_hidden_state\n",
    "#     print(sequence_output)\n",
    "#     # Extract the CLS token\n",
    "#     cls_token = sequence_output[:, 0, :]\n",
    "\n",
    "#     # Output layer for binary classification\n",
    "#     out = Dense(1, activation='sigmoid')(cls_token)\n",
    "\n",
    "#     # Define the model\n",
    "#     model = Model(inputs=[input_word_ids, attention_mask], outputs=out)\n",
    "    \n",
    "#     # Compile the model\n",
    "#     model.compile(Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import TFDistilBertModel\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Initialize transformer model\n",
    "# transformer = TFDistilBertModel.from_pretrained('distilbert-base-multilingual-cased')\n",
    "# print(transformer) \n",
    "\n",
    "# #Define input layers\n",
    "# # max_len = 192  # Example length, adjust as needed\n",
    "# # input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name='input_word_ids')\n",
    "# # attention_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "# # print(input_word_ids)\n",
    "# # # Get transformer output (correct usage of call method)\n",
    "# #transformer_output = transformer(input_ids=input_word_ids, attention_mask=attention_mask)\n",
    "# transformer_output = transformer(x_train, attention_masks_train)\n",
    "\n",
    "# # # Extract last hidden state\n",
    "# # sequence_output = transformer_output['last_hidden_state']\n",
    "\n",
    "# # # Get [CLS] token for classification\n",
    "# # cls_token = sequence_output[:, 0, :]  # Shape: (batch_size, hidden_size)\n",
    "\n",
    "# # # Define output layer (for binary classification)\n",
    "# # out = tf.keras.layers.Dense(1, activation='sigmoid')(cls_token)\n",
    "\n",
    "# # # Build and compile model\n",
    "# # model = tf.keras.Model(inputs=[input_word_ids, attention_mask], outputs=out)\n",
    "# # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_layer=(transformers.TFDistilBertModel.from_pretrained('distilbert-base-multilingual-cased'))\n",
    "# model=build_model(transformer_layer,max_len=192)\n",
    "# model.summary \n",
    "\n",
    "\n",
    "# model = build_model(transformer,max_len=max_len)\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kusha\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kusha\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "    'input_ids': x_train,\n",
    "    'attention_mask': train_mask\n",
    "}, y_train_clipped)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kusha\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\optimizers\\__init__.py:317: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = Adam(learning_rate=2e-5)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\kusha\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\kusha\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=x_train.shape[0]//BATCH_SIZE\n",
    "\n",
    "train_history=model.fit(train_dataset,steps_per_epoch=n_steps,validation_data=valid_dataset,epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=x_valid.shape[0]//BATCH_SIZE\n",
    "train_history_2=model.fit(valid_dataset.repeat(),steps_per_epoch=n_steps,epochs=EPOCHS*2)\n",
    "\n",
    "predictions=model.predict(test_dataset,verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
